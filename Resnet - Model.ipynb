{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a967c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170915f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('data_ingestion')\n",
    "from data_ingestion import data_ingestion_for_big_dataset, data_ingestion_pipeline_smaller_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bad3ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFERENCE_PATH = './trained_pytorch_model/resnet_finetuned_smaller_dataset.pth'\n",
    "INFERENCE_PATH_FOR_BIGGER_DATASET = './trained_pytorch_model/resnet_finetuned_bigger_dataset.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5db9474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/pyuvraj/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/pyuvraj/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/pyuvraj/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f591a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# set device to be cuda if available, otherwise it will be set to cpu\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "135e38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators - Small Nudity Dataset\n",
    "training_set = data_pipeline_pytorch_smaller_dataset.training_dataset\n",
    "training_generator = data_pipeline_pytorch_smaller_dataset.train_dataloader\n",
    "validation_set = data_pipeline_pytorch_smaller_dataset.val_dataset\n",
    "validation_generator = data_pipeline_pytorch_smaller_dataset.val_dataloader\n",
    "dataloaders = {'train': training_generator, 'val': validation_generator}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d69b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators - Large Nudity Dataset\n",
    "training_set = data_ingestion_for_big_dataset.training_dataset\n",
    "training_generator = data_ingestion_for_big_dataset.train_dataloader\n",
    "validation_set = data_ingestion_for_big_dataset.val_dataset\n",
    "validation_generator = data_ingestion_for_big_dataset.val_dataloader\n",
    "dataloaders = {'train': training_generator, 'val': validation_generator}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fec0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "loss iteration ->  5 0.2023783177137375\n",
      "loss iteration ->  10 0.13433001935482025\n",
      "loss iteration ->  15 0.20007950067520142\n",
      "loss iteration ->  20 0.12698262929916382\n",
      "loss iteration ->  25 0.3564136326313019\n",
      "loss iteration ->  30 0.18685854971408844\n",
      "loss iteration ->  35 0.07465089857578278\n",
      "loss iteration ->  40 0.2087007462978363\n",
      "loss iteration ->  45 0.19297254085540771\n",
      "loss iteration ->  50 0.303440660238266\n",
      "loss iteration ->  55 0.36875954270362854\n",
      "loss iteration ->  60 0.10443352907896042\n",
      "loss iteration ->  65 0.32403597235679626\n",
      "loss iteration ->  70 0.1242697536945343\n",
      "loss iteration ->  75 0.16409790515899658\n",
      "loss iteration ->  80 0.15111762285232544\n",
      "loss iteration ->  85 0.3254172205924988\n",
      "loss iteration ->  90 0.31990185379981995\n",
      "loss iteration ->  95 0.27288588881492615\n",
      "loss iteration ->  100 0.12771248817443848\n",
      "loss iteration ->  105 0.29708731174468994\n",
      "loss iteration ->  110 0.15137290954589844\n",
      "loss iteration ->  115 0.0774708017706871\n",
      "loss iteration ->  120 0.18728098273277283\n",
      "loss iteration ->  125 0.16960380971431732\n",
      "loss iteration ->  130 0.2642708122730255\n",
      "loss iteration ->  135 0.19282621145248413\n",
      "loss iteration ->  140 0.08004263043403625\n",
      "loss iteration ->  145 0.24818775057792664\n",
      "loss iteration ->  150 0.20141269266605377\n",
      "loss iteration ->  155 0.08630254864692688\n",
      "loss iteration ->  160 0.33120718598365784\n",
      "loss iteration ->  165 0.09042957425117493\n",
      "loss iteration ->  170 0.08090364933013916\n",
      "loss iteration ->  175 0.07254913449287415\n",
      "loss iteration ->  180 0.11118070781230927\n",
      "loss iteration ->  185 0.12433421611785889\n",
      "loss iteration ->  190 0.24553938210010529\n",
      "loss iteration ->  195 0.13516998291015625\n",
      "loss iteration ->  200 0.04061242565512657\n",
      "loss iteration ->  205 0.0948895812034607\n",
      "loss iteration ->  210 0.12267212569713593\n",
      "loss iteration ->  215 0.11594884097576141\n",
      "loss iteration ->  220 0.3322502672672272\n",
      "loss iteration ->  225 0.06485999375581741\n",
      "loss iteration ->  230 0.18147026002407074\n",
      "loss iteration ->  235 0.14093802869319916\n",
      "loss iteration ->  240 0.2616274654865265\n",
      "loss iteration ->  245 0.2652779519557953\n",
      "loss iteration ->  250 0.2587663531303406\n",
      "loss iteration ->  255 0.2879772186279297\n",
      "loss iteration ->  260 0.19097042083740234\n",
      "loss iteration ->  265 0.18444234132766724\n",
      "loss iteration ->  270 0.08298482745885849\n",
      "loss iteration ->  275 0.12366888672113419\n",
      "loss iteration ->  280 0.21497943997383118\n",
      "loss iteration ->  285 0.04225386306643486\n",
      "loss iteration ->  290 0.12046405673027039\n",
      "loss iteration ->  295 0.16629044711589813\n",
      "loss iteration ->  300 0.21508504450321198\n",
      "loss iteration ->  305 0.14116457104682922\n",
      "loss iteration ->  310 0.1751709133386612\n",
      "loss iteration ->  315 0.09139084815979004\n",
      "loss iteration ->  320 0.1413210928440094\n",
      "loss iteration ->  325 0.42156773805618286\n",
      "loss iteration ->  330 0.14164763689041138\n",
      "loss iteration ->  335 0.1331847757101059\n",
      "loss iteration ->  340 0.17834171652793884\n",
      "loss iteration ->  345 0.11269177496433258\n",
      "loss iteration ->  350 0.1407063752412796\n",
      "loss iteration ->  355 0.2950071692466736\n",
      "loss iteration ->  360 0.3618931770324707\n",
      "loss iteration ->  365 0.42285221815109253\n",
      "loss iteration ->  370 0.07732116430997849\n",
      "loss iteration ->  375 0.34342965483665466\n",
      "loss iteration ->  380 0.19482871890068054\n",
      "loss iteration ->  385 0.07645455747842789\n",
      "loss iteration ->  390 0.16153161227703094\n",
      "loss iteration ->  395 0.1490170806646347\n",
      "loss iteration ->  400 0.18765726685523987\n",
      "loss iteration ->  405 0.06230805814266205\n",
      "loss iteration ->  410 0.11087300628423691\n",
      "loss iteration ->  415 0.11003677546977997\n",
      "loss iteration ->  420 0.103413425385952\n",
      "loss iteration ->  425 0.09184793382883072\n",
      "loss iteration ->  430 0.1305563747882843\n",
      "loss iteration ->  435 0.1897132694721222\n",
      "loss iteration ->  440 0.17635808885097504\n",
      "loss iteration ->  445 0.23200596868991852\n",
      "loss iteration ->  450 0.28214579820632935\n",
      "loss iteration ->  455 0.09529675543308258\n",
      "loss iteration ->  460 0.14862631261348724\n",
      "loss iteration ->  465 0.07818011194467545\n",
      "loss iteration ->  470 0.18541674315929413\n",
      "loss iteration ->  475 0.16738253831863403\n",
      "loss iteration ->  480 0.2769775986671448\n",
      "loss iteration ->  485 0.15991626679897308\n",
      "loss iteration ->  490 0.22177305817604065\n",
      "loss iteration ->  495 0.16751326620578766\n",
      "loss iteration ->  500 0.24163693189620972\n",
      "loss iteration ->  505 0.18404319882392883\n",
      "loss iteration ->  510 0.1283213347196579\n",
      "loss iteration ->  515 0.3275173306465149\n",
      "loss iteration ->  520 0.10687139630317688\n",
      "loss iteration ->  525 0.3075549304485321\n",
      "loss iteration ->  530 0.15961062908172607\n",
      "loss iteration ->  535 0.22117646038532257\n",
      "loss iteration ->  540 0.12478282302618027\n",
      "loss iteration ->  545 0.0967165157198906\n",
      "loss iteration ->  550 0.10674682259559631\n",
      "loss iteration ->  555 0.07033815234899521\n",
      "loss iteration ->  560 0.1773073375225067\n",
      "loss iteration ->  565 0.08125591278076172\n",
      "loss iteration ->  570 0.09458670020103455\n",
      "loss iteration ->  575 0.14976628124713898\n",
      "loss iteration ->  580 0.04808575659990311\n",
      "loss iteration ->  585 0.20375150442123413\n",
      "loss iteration ->  590 0.16460582613945007\n",
      "loss iteration ->  595 0.06878798454999924\n",
      "loss iteration ->  600 0.17156752943992615\n",
      "loss iteration ->  605 0.1725417524576187\n",
      "loss iteration ->  610 0.08019700646400452\n",
      "loss iteration ->  615 0.16319014132022858\n",
      "loss iteration ->  620 0.1186748668551445\n",
      "loss iteration ->  625 0.13144366443157196\n",
      "loss iteration ->  630 0.2747349143028259\n",
      "loss iteration ->  635 0.2130207121372223\n",
      "loss iteration ->  640 0.0720352977514267\n",
      "loss iteration ->  645 0.29582494497299194\n",
      "loss iteration ->  650 0.08408917486667633\n",
      "loss iteration ->  655 0.20758946239948273\n",
      "loss iteration ->  660 0.20691220462322235\n",
      "loss iteration ->  665 0.11021686345338821\n",
      "loss iteration ->  670 0.22899988293647766\n",
      "loss iteration ->  675 0.3966960608959198\n",
      "loss iteration ->  680 0.3958714008331299\n",
      "loss iteration ->  685 0.2428036630153656\n",
      "loss iteration ->  690 0.1353110671043396\n",
      "loss iteration ->  695 0.16950663924217224\n",
      "loss iteration ->  700 0.05001159384846687\n",
      "loss iteration ->  705 0.1571952998638153\n",
      "loss iteration ->  710 0.24278245866298676\n",
      "loss iteration ->  715 0.25715261697769165\n",
      "loss iteration ->  720 0.09362391382455826\n",
      "loss iteration ->  725 0.05378410965204239\n",
      "loss iteration ->  730 0.23366881906986237\n",
      "loss iteration ->  735 0.15576069056987762\n",
      "loss iteration ->  740 0.18013708293437958\n",
      "loss iteration ->  745 0.06194040924310684\n",
      "loss iteration ->  750 0.09258730709552765\n",
      "loss iteration ->  755 0.12069615721702576\n",
      "loss iteration ->  760 0.14332151412963867\n",
      "loss iteration ->  765 0.18357568979263306\n",
      "loss iteration ->  770 0.06560003757476807\n",
      "loss iteration ->  775 0.09840010106563568\n",
      "loss iteration ->  780 0.05074692890048027\n",
      "loss iteration ->  785 0.11865341663360596\n",
      "loss iteration ->  790 0.08685316890478134\n",
      "loss iteration ->  795 0.17443175613880157\n",
      "loss iteration ->  800 0.09382027387619019\n",
      "loss iteration ->  805 0.3772226572036743\n",
      "loss iteration ->  810 0.1281563937664032\n",
      "loss iteration ->  815 0.13210149109363556\n",
      "loss iteration ->  820 0.22849483788013458\n",
      "loss iteration ->  825 0.20994961261749268\n",
      "loss iteration ->  830 0.0987267941236496\n",
      "loss iteration ->  835 0.1736299991607666\n",
      "loss iteration ->  840 0.29922541975975037\n",
      "loss iteration ->  845 0.27760761976242065\n",
      "loss iteration ->  850 0.09787054359912872\n",
      "loss iteration ->  855 0.037754982709884644\n",
      "loss iteration ->  860 0.04486310854554176\n",
      "loss iteration ->  865 0.24985823035240173\n",
      "loss iteration ->  870 0.19445781409740448\n",
      "loss iteration ->  875 0.15858182311058044\n",
      "loss iteration ->  880 0.1321001797914505\n",
      "loss iteration ->  885 0.23614877462387085\n",
      "loss iteration ->  890 0.043999314308166504\n",
      "loss iteration ->  895 0.12861794233322144\n",
      "loss iteration ->  900 0.3110807538032532\n",
      "loss iteration ->  905 0.09647620469331741\n",
      "loss iteration ->  910 0.10921560227870941\n",
      "loss iteration ->  915 0.15519067645072937\n",
      "loss iteration ->  920 0.13136018812656403\n",
      "loss iteration ->  925 0.11636286228895187\n",
      "loss iteration ->  930 0.1290772259235382\n",
      "loss iteration ->  935 0.3089132606983185\n",
      "loss iteration ->  940 0.11689244955778122\n",
      "loss iteration ->  945 0.19304245710372925\n",
      "loss iteration ->  950 0.15679581463336945\n",
      "loss iteration ->  955 0.16138416528701782\n",
      "loss iteration ->  960 0.17955616116523743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  965 0.2506457269191742\n",
      "loss iteration ->  970 0.24701598286628723\n",
      "loss iteration ->  975 0.1068802922964096\n",
      "loss iteration ->  980 0.23213085532188416\n",
      "loss iteration ->  985 0.1346988081932068\n",
      "loss iteration ->  990 0.1859842985868454\n",
      "loss iteration ->  995 0.17438846826553345\n",
      "loss iteration ->  1000 0.1087697222828865\n",
      "loss iteration ->  1005 0.0466451495885849\n",
      "loss iteration ->  1010 0.19985680282115936\n",
      "loss iteration ->  1015 0.15210452675819397\n",
      "loss iteration ->  1020 0.1939258575439453\n",
      "loss iteration ->  1025 0.10882598906755447\n",
      "loss iteration ->  1030 0.2519749104976654\n",
      "loss iteration ->  1035 0.36774611473083496\n",
      "loss iteration ->  1040 0.6734572052955627\n",
      "loss iteration ->  1045 0.06230933219194412\n",
      "loss iteration ->  1050 0.062322065234184265\n",
      "loss iteration ->  1055 0.21298614144325256\n",
      "loss iteration ->  1060 0.08944787085056305\n",
      "loss iteration ->  1065 0.16158899664878845\n",
      "loss iteration ->  1070 0.18918311595916748\n",
      "loss iteration ->  1075 0.10481712222099304\n",
      "loss iteration ->  1080 0.06590752303600311\n",
      "loss iteration ->  1085 0.0884213000535965\n",
      "loss iteration ->  1090 0.3357657492160797\n",
      "loss iteration ->  1095 0.10490711033344269\n",
      "loss iteration ->  1100 0.20863698422908783\n",
      "loss iteration ->  1105 0.08465899527072906\n",
      "loss iteration ->  1110 0.12306161224842072\n",
      "loss iteration ->  1115 0.3096845746040344\n",
      "loss iteration ->  1120 0.1663568615913391\n",
      "loss iteration ->  1125 0.08535384386777878\n",
      "loss iteration ->  1130 0.09004482626914978\n",
      "loss iteration ->  1135 0.24392937123775482\n",
      "loss iteration ->  1140 0.2712237238883972\n",
      "loss iteration ->  1145 0.03675057739019394\n",
      "loss iteration ->  1150 0.1864507794380188\n",
      "loss iteration ->  1155 0.39963674545288086\n",
      "loss iteration ->  1160 0.05544053390622139\n",
      "loss iteration ->  1165 0.04819406196475029\n",
      "loss iteration ->  1170 0.08435630053281784\n",
      "loss iteration ->  1175 0.2667827606201172\n",
      "loss iteration ->  1180 0.10556413233280182\n",
      "loss iteration ->  1185 0.23446743190288544\n",
      "loss iteration ->  1190 0.15861904621124268\n",
      "loss iteration ->  1195 0.08171325922012329\n",
      "loss iteration ->  1200 0.2135399878025055\n",
      "loss iteration ->  1205 0.17112526297569275\n",
      "loss iteration ->  1210 0.17377856373786926\n",
      "loss iteration ->  1215 0.13388462364673615\n",
      "loss iteration ->  1220 0.10567867755889893\n",
      "loss iteration ->  1225 0.17639976739883423\n",
      "loss iteration ->  1230 0.12704946100711823\n",
      "loss iteration ->  1235 0.05047270283102989\n",
      "loss iteration ->  1240 0.07714021950960159\n",
      "loss iteration ->  1245 0.26478540897369385\n",
      "loss iteration ->  1250 0.04864618927240372\n",
      "loss iteration ->  1255 0.18013398349285126\n",
      "loss iteration ->  1260 0.16690415143966675\n",
      "loss iteration ->  1265 0.09786456823348999\n",
      "loss iteration ->  1270 0.03835725784301758\n",
      "loss iteration ->  1275 0.3243497610092163\n",
      "loss iteration ->  1280 0.10925574600696564\n",
      "loss iteration ->  1285 0.15835417807102203\n",
      "loss iteration ->  1290 0.2943509817123413\n",
      "loss iteration ->  1295 0.33273202180862427\n",
      "loss iteration ->  1300 0.13606375455856323\n",
      "loss iteration ->  1305 0.24550454318523407\n",
      "loss iteration ->  1310 0.12438086420297623\n",
      "loss iteration ->  1315 0.12578792870044708\n",
      "loss iteration ->  1320 0.15488289296627045\n",
      "loss iteration ->  1325 0.11681739240884781\n",
      "loss iteration ->  1330 0.2705814838409424\n",
      "loss iteration ->  1335 0.20927882194519043\n",
      "loss iteration ->  1340 0.13330209255218506\n",
      "loss iteration ->  1345 0.07665878534317017\n",
      "loss iteration ->  1350 0.04630677029490471\n",
      "loss iteration ->  1355 0.229409858584404\n",
      "loss iteration ->  1360 0.09037908166646957\n",
      "loss iteration ->  1365 0.04414461553096771\n",
      "loss iteration ->  1370 0.10796300321817398\n",
      "loss iteration ->  1375 0.07235059887170792\n",
      "loss iteration ->  1380 0.08478649705648422\n",
      "loss iteration ->  1385 0.1451902985572815\n",
      "loss iteration ->  1390 0.15180057287216187\n",
      "loss iteration ->  1395 0.08499623835086823\n",
      "loss iteration ->  1400 0.2710587978363037\n",
      "loss iteration ->  1405 0.4458019435405731\n",
      "loss iteration ->  1410 0.21158096194267273\n",
      "loss iteration ->  1415 0.06798473745584488\n",
      "loss iteration ->  1420 0.03341878950595856\n",
      "loss iteration ->  1425 0.09744425117969513\n",
      "loss iteration ->  1430 0.08434220403432846\n",
      "loss iteration ->  1435 0.14334504306316376\n",
      "loss iteration ->  1440 0.10792111605405807\n",
      "loss iteration ->  1445 0.07946448773145676\n",
      "loss iteration ->  1450 0.13481976091861725\n",
      "loss iteration ->  1455 0.4011559784412384\n",
      "loss iteration ->  1460 0.16826856136322021\n",
      "loss iteration ->  1465 0.057200416922569275\n",
      "loss iteration ->  1470 0.13186362385749817\n",
      "loss iteration ->  1475 0.10456274449825287\n",
      "loss iteration ->  1480 0.09968999028205872\n",
      "loss iteration ->  1485 0.09032131731510162\n",
      "loss iteration ->  1490 0.3719237744808197\n",
      "loss iteration ->  1495 0.1243099495768547\n",
      "loss iteration ->  1500 0.11103744804859161\n",
      "loss iteration ->  1505 0.024008505046367645\n",
      "loss iteration ->  1510 0.2977979779243469\n",
      "loss iteration ->  1515 0.3282414972782135\n",
      "loss iteration ->  1520 0.03337528556585312\n",
      "loss iteration ->  1525 0.10379127413034439\n",
      "loss iteration ->  1530 0.15886592864990234\n",
      "loss iteration ->  1535 0.18823370337486267\n",
      "loss iteration ->  1540 0.08145296573638916\n",
      "loss iteration ->  1545 0.10424333810806274\n",
      "loss iteration ->  1550 0.16347698867321014\n",
      "loss iteration ->  1555 0.05489274486899376\n",
      "loss iteration ->  1560 0.1717168390750885\n",
      "loss iteration ->  1565 0.18851599097251892\n",
      "loss iteration ->  1570 0.20551139116287231\n",
      "loss iteration ->  1575 0.12451068311929703\n",
      "loss iteration ->  1580 0.12697133421897888\n",
      "loss iteration ->  1585 0.0524962916970253\n",
      "loss iteration ->  1590 0.0965019017457962\n",
      "loss iteration ->  1595 0.14513634145259857\n",
      "loss iteration ->  1600 0.15133309364318848\n",
      "loss iteration ->  1605 0.31104937195777893\n",
      "loss iteration ->  1610 0.11296441406011581\n",
      "loss iteration ->  1615 0.5187417268753052\n",
      "loss iteration ->  1620 0.07814658433198929\n",
      "loss iteration ->  1625 0.05510219186544418\n",
      "loss iteration ->  1630 0.05654837563633919\n",
      "loss iteration ->  1635 0.16562563180923462\n",
      "loss iteration ->  1640 0.20632606744766235\n",
      "loss iteration ->  1645 0.059690214693546295\n",
      "loss iteration ->  1650 0.19318878650665283\n",
      "loss iteration ->  1655 0.1219390332698822\n",
      "loss iteration ->  1660 0.09678302705287933\n",
      "loss iteration ->  1665 0.17782634496688843\n",
      "loss iteration ->  1670 0.07073303312063217\n",
      "loss iteration ->  1675 0.12763281166553497\n",
      "loss iteration ->  1680 0.06661543995141983\n",
      "loss iteration ->  1685 0.04760313779115677\n",
      "loss iteration ->  1690 0.046174369752407074\n",
      "loss iteration ->  1695 0.1310126930475235\n",
      "loss iteration ->  1700 0.07441733032464981\n",
      "loss iteration ->  1705 0.1799466460943222\n",
      "loss iteration ->  1710 0.24134668707847595\n",
      "loss iteration ->  1715 0.1875976324081421\n",
      "loss iteration ->  1720 0.13705237209796906\n",
      "loss iteration ->  1725 0.08592943102121353\n",
      "loss iteration ->  1730 0.12099317461252213\n",
      "loss iteration ->  1735 0.07057399302721024\n",
      "loss iteration ->  1740 0.11837540566921234\n",
      "loss iteration ->  1745 0.1004076898097992\n",
      "loss iteration ->  1750 0.05322897434234619\n",
      "loss iteration ->  1755 0.10303018242120743\n",
      "loss iteration ->  1760 0.05565520003437996\n",
      "loss iteration ->  1765 0.1989465206861496\n",
      "loss iteration ->  1770 0.090118408203125\n",
      "loss iteration ->  1775 0.2724854648113251\n",
      "loss iteration ->  1780 0.03556289151310921\n",
      "loss iteration ->  1785 0.15551355481147766\n",
      "loss iteration ->  1790 0.22390395402908325\n",
      "loss iteration ->  1795 0.2614689767360687\n",
      "loss iteration ->  1800 0.09296899288892746\n",
      "loss iteration ->  1805 0.10349395126104355\n",
      "loss iteration ->  1810 0.05882105603814125\n",
      "loss iteration ->  1815 0.03984101489186287\n",
      "loss iteration ->  1820 0.05758024752140045\n",
      "loss iteration ->  1825 0.05129271000623703\n",
      "loss iteration ->  1830 0.19844013452529907\n",
      "loss iteration ->  1835 0.2039998173713684\n",
      "loss iteration ->  1840 0.1622905731201172\n",
      "loss iteration ->  1845 0.18690437078475952\n",
      "loss iteration ->  1850 0.35354042053222656\n",
      "loss iteration ->  1855 0.04433131217956543\n",
      "loss iteration ->  1860 0.13520514965057373\n",
      "loss iteration ->  1865 0.08349694311618805\n",
      "loss iteration ->  1870 0.17802947759628296\n",
      "loss iteration ->  1875 0.06408534944057465\n",
      "loss iteration ->  1880 0.10000447928905487\n",
      "loss iteration ->  1885 0.21921220421791077\n",
      "loss iteration ->  1890 0.0937528908252716\n",
      "loss iteration ->  1895 0.19572322070598602\n",
      "loss iteration ->  1900 0.06626855581998825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  1905 0.06298721581697464\n",
      "loss iteration ->  1910 0.06345494836568832\n",
      "loss iteration ->  1915 0.20485331118106842\n",
      "loss iteration ->  1920 0.09961772710084915\n",
      "loss iteration ->  1925 0.04484044015407562\n",
      "loss iteration ->  1930 0.14112739264965057\n",
      "loss iteration ->  1935 0.22244180738925934\n",
      "loss iteration ->  1940 0.04445759579539299\n",
      "loss iteration ->  1945 0.08971220254898071\n",
      "loss iteration ->  1950 0.0620267353951931\n",
      "loss iteration ->  1955 0.05902067944407463\n",
      "loss iteration ->  1960 0.3548986315727234\n",
      "loss iteration ->  1965 0.09406425058841705\n",
      "loss iteration ->  1970 0.16036789119243622\n",
      "loss iteration ->  1975 0.07922035455703735\n",
      "loss iteration ->  1980 0.04992000013589859\n",
      "loss iteration ->  1985 0.14464381337165833\n",
      "loss iteration ->  1990 0.20290061831474304\n",
      "loss iteration ->  1995 0.10519041866064072\n",
      "loss iteration ->  2000 0.07647629827260971\n",
      "loss iteration ->  2005 0.02750280871987343\n",
      "loss iteration ->  2010 0.057599809020757675\n",
      "loss iteration ->  2015 0.13081291317939758\n",
      "loss iteration ->  2020 0.06051880493760109\n",
      "loss iteration ->  2025 0.05663907527923584\n",
      "loss iteration ->  2030 0.22577576339244843\n",
      "loss iteration ->  2035 0.07563811540603638\n",
      "loss iteration ->  2040 0.07332263886928558\n",
      "loss iteration ->  2045 0.18448999524116516\n",
      "loss iteration ->  2050 0.09042225778102875\n",
      "loss iteration ->  2055 0.28321322798728943\n",
      "loss iteration ->  2060 0.26690393686294556\n",
      "loss iteration ->  2065 0.08542923629283905\n",
      "loss iteration ->  2070 0.08679565042257309\n",
      "loss iteration ->  2075 0.06396304816007614\n",
      "loss iteration ->  2080 0.042426981031894684\n",
      "loss iteration ->  2085 0.09059493243694305\n",
      "loss iteration ->  2090 0.12194011360406876\n",
      "loss iteration ->  2095 0.11250714212656021\n",
      "loss iteration ->  2100 0.19701574742794037\n",
      "loss iteration ->  2105 0.21125651895999908\n",
      "loss iteration ->  2110 0.19072918593883514\n",
      "loss iteration ->  2115 0.23862004280090332\n",
      "loss iteration ->  2120 0.2227342128753662\n",
      "loss iteration ->  2125 0.07852162420749664\n",
      "loss iteration ->  2130 0.12819479405879974\n",
      "loss iteration ->  2135 0.13573779165744781\n",
      "loss iteration ->  2140 0.15951253473758698\n",
      "loss iteration ->  2145 0.19638918340206146\n",
      "loss iteration ->  2150 0.25017958879470825\n",
      "loss iteration ->  2155 0.19938836991786957\n",
      "loss iteration ->  2160 0.17369133234024048\n",
      "loss iteration ->  2165 0.0410844050347805\n",
      "loss iteration ->  2170 0.031583335250616074\n",
      "loss iteration ->  2175 0.05490301921963692\n",
      "loss iteration ->  2180 0.06661026924848557\n",
      "loss iteration ->  2185 0.07914707064628601\n",
      "loss iteration ->  2190 0.31071823835372925\n",
      "loss iteration ->  2195 0.15470172464847565\n",
      "loss iteration ->  2200 0.11618401110172272\n",
      "loss iteration ->  2205 0.04482509195804596\n",
      "loss iteration ->  2210 0.11747828125953674\n",
      "loss iteration ->  2215 0.1577363759279251\n",
      "loss iteration ->  2220 0.10995156317949295\n",
      "loss iteration ->  2225 0.04424174875020981\n",
      "loss iteration ->  2230 0.14892573654651642\n",
      "loss iteration ->  2235 0.12523984909057617\n",
      "loss iteration ->  2240 0.09803228080272675\n",
      "loss iteration ->  2245 0.38733533024787903\n",
      "loss iteration ->  2250 0.07365233451128006\n",
      "loss iteration ->  2255 0.033808860927820206\n",
      "loss iteration ->  2260 0.050695694983005524\n",
      "loss iteration ->  2265 0.04398158937692642\n",
      "loss iteration ->  2270 0.09871043264865875\n",
      "loss iteration ->  2275 0.2818540036678314\n",
      "loss iteration ->  2280 0.1517263501882553\n",
      "loss iteration ->  2285 0.26330995559692383\n",
      "loss iteration ->  2290 0.121070496737957\n",
      "loss iteration ->  2295 0.04092497006058693\n",
      "loss iteration ->  2300 0.09886284172534943\n",
      "loss iteration ->  2305 0.2199728786945343\n",
      "loss iteration ->  2310 0.08235727995634079\n",
      "loss iteration ->  2315 0.06216660887002945\n",
      "loss iteration ->  2320 0.1160086914896965\n",
      "loss iteration ->  2325 0.10305330902338028\n",
      "loss iteration ->  2330 0.03294611722230911\n",
      "loss iteration ->  2335 0.14714182913303375\n",
      "loss iteration ->  2340 0.0863429605960846\n",
      "loss iteration ->  2345 0.2059997320175171\n",
      "loss iteration ->  2350 0.25431129336357117\n",
      "loss iteration ->  2355 0.1717837005853653\n",
      "loss iteration ->  2360 0.10584329813718796\n",
      "loss iteration ->  2365 0.06326707452535629\n",
      "loss iteration ->  2370 0.29828643798828125\n",
      "loss iteration ->  2375 0.05906204879283905\n",
      "loss iteration ->  2380 0.1022326648235321\n",
      "loss iteration ->  2385 0.23949529230594635\n",
      "loss iteration ->  2390 0.17864270508289337\n",
      "loss iteration ->  2395 0.14539219439029694\n",
      "loss iteration ->  2400 0.12006569653749466\n",
      "loss iteration ->  2405 0.12108401209115982\n",
      "loss iteration ->  2410 0.04119682312011719\n",
      "loss iteration ->  2415 0.07636865973472595\n",
      "loss iteration ->  2420 0.1594829112291336\n",
      "loss iteration ->  2425 0.2303844541311264\n",
      "loss iteration ->  2430 0.19330854713916779\n",
      "loss iteration ->  2435 0.112650565803051\n",
      "loss iteration ->  2440 0.17400586605072021\n",
      "loss iteration ->  2445 0.10636380314826965\n",
      "loss iteration ->  2450 0.15554331243038177\n",
      "loss iteration ->  2455 0.06669406592845917\n",
      "loss iteration ->  2460 0.11056555062532425\n",
      "loss iteration ->  2465 0.07523026317358017\n",
      "loss iteration ->  2470 0.0636095181107521\n",
      "loss iteration ->  2475 0.03448079153895378\n",
      "loss iteration ->  2480 0.0355110839009285\n",
      "loss iteration ->  2485 0.05442788824439049\n",
      "loss iteration ->  2490 0.2283410131931305\n",
      "loss iteration ->  2495 0.03282609581947327\n",
      "loss iteration ->  2500 0.27587997913360596\n",
      "loss iteration ->  2505 0.23157811164855957\n",
      "loss iteration ->  2510 0.17462722957134247\n",
      "loss iteration ->  2515 0.051840927451848984\n",
      "loss iteration ->  2520 0.18873274326324463\n",
      "loss iteration ->  2525 0.43926292657852173\n",
      "loss iteration ->  2530 0.12660004198551178\n",
      "loss iteration ->  2535 0.6038380861282349\n",
      "loss iteration ->  2540 0.07773825526237488\n",
      "loss iteration ->  2545 0.03693743422627449\n",
      "loss iteration ->  2550 0.21936149895191193\n",
      "loss iteration ->  2555 0.11875925958156586\n",
      "loss iteration ->  2560 0.25741055607795715\n",
      "loss iteration ->  2565 0.08262993395328522\n",
      "loss iteration ->  2570 0.09762738645076752\n",
      "loss iteration ->  2575 0.06561221927404404\n",
      "loss iteration ->  2580 0.16111767292022705\n",
      "loss iteration ->  2585 0.3569217026233673\n",
      "loss iteration ->  2590 0.12646110355854034\n",
      "loss iteration ->  2595 0.1840907782316208\n",
      "loss iteration ->  2600 0.10878591984510422\n",
      "loss iteration ->  2605 0.11206550151109695\n",
      "loss iteration ->  2610 0.23976057767868042\n",
      "loss iteration ->  2615 0.0903736799955368\n",
      "loss iteration ->  2620 0.24057790637016296\n",
      "loss iteration ->  2625 0.05522327870130539\n",
      "loss iteration ->  2630 0.1921793818473816\n",
      "loss iteration ->  2635 0.04455764591693878\n",
      "loss iteration ->  2640 0.13083910942077637\n",
      "loss iteration ->  2645 0.07862946391105652\n",
      "loss iteration ->  2650 0.13581986725330353\n",
      "loss iteration ->  2655 0.12754617631435394\n",
      "loss iteration ->  2660 0.35365426540374756\n",
      "loss iteration ->  2665 0.4000648856163025\n",
      "loss iteration ->  2670 0.08135538548231125\n",
      "loss iteration ->  2675 0.11254681646823883\n",
      "loss iteration ->  2680 0.22347906231880188\n",
      "loss iteration ->  2685 0.13817614316940308\n",
      "loss iteration ->  2690 0.13306021690368652\n",
      "loss iteration ->  2695 0.0861661285161972\n",
      "loss iteration ->  2700 0.0662001222372055\n",
      "loss iteration ->  2705 0.12373699247837067\n",
      "loss iteration ->  2710 0.0772002637386322\n",
      "loss iteration ->  2715 0.07458341866731644\n",
      "loss iteration ->  2720 0.09344632178544998\n",
      "loss iteration ->  2725 0.03041568212211132\n",
      "loss iteration ->  2730 0.07545512169599533\n",
      "loss iteration ->  2735 0.07157482951879501\n",
      "loss iteration ->  2740 0.08536665141582489\n",
      "loss iteration ->  2745 0.2691972255706787\n",
      "loss iteration ->  2750 0.11201286315917969\n",
      "loss iteration ->  2755 0.23756776750087738\n",
      "loss iteration ->  2760 0.09767995774745941\n",
      "loss iteration ->  2765 0.10164640843868256\n",
      "loss iteration ->  2770 0.23356135189533234\n",
      "loss iteration ->  2775 0.05026799812912941\n",
      "loss iteration ->  2780 0.07148212939500809\n",
      "loss iteration ->  2785 0.05869923159480095\n",
      "loss iteration ->  2790 0.20983415842056274\n",
      "loss iteration ->  2795 0.07024802267551422\n",
      "loss iteration ->  2800 0.15928718447685242\n",
      "loss iteration ->  2805 0.10119587928056717\n",
      "loss iteration ->  2810 0.16876710951328278\n",
      "loss iteration ->  2815 0.06766754388809204\n",
      "loss iteration ->  2820 0.048597611486911774\n",
      "loss iteration ->  2825 0.16863968968391418\n",
      "loss iteration ->  2830 0.11207486689090729\n",
      "loss iteration ->  2835 0.37772291898727417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  2840 0.13426627218723297\n",
      "loss iteration ->  2845 0.12173186242580414\n",
      "loss iteration ->  2850 0.44073042273521423\n",
      "loss iteration ->  2855 0.07631254196166992\n",
      "loss iteration ->  2860 0.11913534253835678\n",
      "loss iteration ->  2865 0.23984715342521667\n",
      "loss iteration ->  2870 0.09433590620756149\n",
      "loss iteration ->  2875 0.07061593234539032\n",
      "loss iteration ->  2880 0.06401565670967102\n",
      "loss iteration ->  2885 0.07782591134309769\n",
      "loss iteration ->  2890 0.02255364879965782\n",
      "loss iteration ->  2895 0.2079150527715683\n",
      "loss iteration ->  2900 0.02587568201124668\n",
      "loss iteration ->  2905 0.23981329798698425\n",
      "loss iteration ->  2910 0.07017521560192108\n",
      "loss iteration ->  2915 0.08271531760692596\n",
      "loss iteration ->  2920 0.1013370156288147\n",
      "loss iteration ->  2925 0.15460751950740814\n",
      "loss iteration ->  2930 0.0996214896440506\n",
      "loss iteration ->  2935 0.029209434986114502\n",
      "loss iteration ->  2940 0.1951584815979004\n",
      "loss iteration ->  2945 0.10669827461242676\n",
      "loss iteration ->  2950 0.26353633403778076\n",
      "loss iteration ->  2955 0.11117077618837357\n",
      "loss iteration ->  2960 0.18869462609291077\n",
      "loss iteration ->  2965 0.0950026661157608\n",
      "loss iteration ->  2970 0.07509493827819824\n",
      "loss iteration ->  2975 0.06043905019760132\n",
      "loss iteration ->  2980 0.20883013308048248\n",
      "loss iteration ->  2985 0.11379373073577881\n",
      "loss iteration ->  2990 0.026853324845433235\n",
      "loss iteration ->  2995 0.11654387414455414\n",
      "loss iteration ->  3000 0.21297553181648254\n",
      "loss iteration ->  3005 0.10055447369813919\n",
      "loss iteration ->  3010 0.10901334881782532\n",
      "loss iteration ->  3015 0.11062655597925186\n",
      "loss iteration ->  3020 0.11344565451145172\n",
      "loss iteration ->  3025 0.07325290143489838\n",
      "loss iteration ->  3030 0.07510855793952942\n",
      "loss iteration ->  3035 0.10285966098308563\n",
      "loss iteration ->  3040 0.11841799318790436\n",
      "loss iteration ->  3045 0.16691896319389343\n",
      "loss iteration ->  3050 0.05971307307481766\n",
      "loss iteration ->  3055 0.12041763216257095\n",
      "loss iteration ->  3060 0.06054992228746414\n",
      "loss iteration ->  3065 0.12923339009284973\n",
      "loss iteration ->  3070 0.08471161127090454\n",
      "loss iteration ->  3075 0.038803406059741974\n",
      "loss iteration ->  3080 0.2749537527561188\n",
      "loss iteration ->  3085 0.1872444748878479\n",
      "loss iteration ->  3090 0.13905881345272064\n",
      "loss iteration ->  3095 0.16876541078090668\n",
      "loss iteration ->  3100 0.13942517340183258\n",
      "loss iteration ->  3105 0.0791749432682991\n",
      "loss iteration ->  3110 0.2544841468334198\n",
      "loss iteration ->  3115 0.0578015111386776\n",
      "loss iteration ->  3120 0.10766065120697021\n",
      "loss iteration ->  3125 0.25388821959495544\n",
      "loss iteration ->  3130 0.18592779338359833\n",
      "loss iteration ->  3135 0.05567269027233124\n",
      "loss iteration ->  3140 0.4465235471725464\n",
      "loss iteration ->  3145 0.20565572381019592\n",
      "loss iteration ->  3150 0.16263824701309204\n",
      "loss iteration ->  3155 0.061980415135622025\n",
      "loss iteration ->  3160 0.09234556555747986\n",
      "loss iteration ->  3165 0.0647091194987297\n",
      "loss iteration ->  3170 0.2537604868412018\n",
      "loss iteration ->  3175 0.03782648220658302\n",
      "loss iteration ->  3180 0.09594074636697769\n",
      "loss iteration ->  3185 0.3001251518726349\n",
      "loss iteration ->  3190 0.174057275056839\n",
      "loss iteration ->  3195 0.08333581686019897\n",
      "loss iteration ->  3200 0.050675369799137115\n",
      "loss iteration ->  3205 0.08396294713020325\n",
      "loss iteration ->  3210 0.21773365139961243\n",
      "loss iteration ->  3215 0.09567242115736008\n",
      "loss iteration ->  3220 0.17336489260196686\n",
      "loss iteration ->  3225 0.10155770927667618\n",
      "loss iteration ->  3230 0.2377701997756958\n",
      "loss iteration ->  3235 0.11162357777357101\n",
      "loss iteration ->  3240 0.12333500385284424\n",
      "loss iteration ->  3245 0.12368430197238922\n",
      "loss iteration ->  3250 0.1955767124891281\n",
      "loss iteration ->  3255 0.1891438066959381\n",
      "loss iteration ->  3260 0.12199831753969193\n",
      "loss iteration ->  3265 0.05635348707437515\n",
      "loss iteration ->  3270 0.10946814715862274\n",
      "loss iteration ->  3275 0.10496509075164795\n",
      "loss iteration ->  3280 0.193199023604393\n",
      "loss iteration ->  3285 0.34584012627601624\n",
      "loss iteration ->  3290 0.1655479371547699\n",
      "loss iteration ->  3295 0.12164848297834396\n",
      "loss iteration ->  3300 0.18898552656173706\n",
      "loss iteration ->  3305 0.28551018238067627\n",
      "loss iteration ->  3310 0.05708392336964607\n",
      "loss iteration ->  3315 0.0376165471971035\n",
      "loss iteration ->  3320 0.04177332669496536\n",
      "loss iteration ->  3325 0.14441333711147308\n",
      "loss iteration ->  3330 0.1945524960756302\n",
      "loss iteration ->  3335 0.2219008207321167\n",
      "loss iteration ->  3340 0.09532169252634048\n",
      "loss iteration ->  3345 0.40507006645202637\n",
      "loss iteration ->  3350 0.1394391655921936\n",
      "loss iteration ->  3355 0.17791789770126343\n",
      "loss iteration ->  3360 0.09021347761154175\n",
      "loss iteration ->  3365 0.09610150754451752\n",
      "loss iteration ->  3370 0.06525477766990662\n",
      "loss iteration ->  3375 0.059288389980793\n",
      "loss iteration ->  3380 0.09707210212945938\n",
      "loss iteration ->  3385 0.11208741366863251\n",
      "loss iteration ->  3390 0.10560230165719986\n",
      "loss iteration ->  3395 0.07058104127645493\n",
      "loss iteration ->  3400 0.11798115074634552\n",
      "loss iteration ->  3405 0.1783035695552826\n",
      "loss iteration ->  3410 0.0675836130976677\n",
      "loss iteration ->  3415 0.08624066412448883\n",
      "loss iteration ->  3420 0.07716520130634308\n",
      "loss iteration ->  3425 0.08069726824760437\n",
      "loss iteration ->  3430 0.1018500104546547\n",
      "loss iteration ->  3435 0.12282700836658478\n",
      "loss iteration ->  3440 0.07348418980836868\n",
      "loss iteration ->  3445 0.17690081894397736\n",
      "loss iteration ->  3450 0.049553658813238144\n",
      "loss iteration ->  3455 0.1710413247346878\n",
      "loss iteration ->  3460 0.0747976154088974\n",
      "loss iteration ->  3465 0.19523277878761292\n",
      "loss iteration ->  3470 0.07891539484262466\n",
      "loss iteration ->  3475 0.042109571397304535\n",
      "loss iteration ->  3480 0.12559917569160461\n",
      "loss iteration ->  3485 0.047147177159786224\n",
      "loss iteration ->  3490 0.13053646683692932\n",
      "loss iteration ->  3495 0.07345707714557648\n",
      "loss iteration ->  3500 0.18880140781402588\n",
      "loss iteration ->  3505 0.11827708780765533\n",
      "loss iteration ->  3510 0.05462965369224548\n",
      "loss iteration ->  3515 0.08724722266197205\n",
      "loss iteration ->  3520 0.07321036607027054\n",
      "loss iteration ->  3525 0.10662148147821426\n",
      "loss iteration ->  3530 0.1612633317708969\n",
      "loss iteration ->  3535 0.20573927462100983\n",
      "loss iteration ->  3540 0.2781742811203003\n",
      "loss iteration ->  3545 0.1640768051147461\n",
      "loss iteration ->  3550 0.03080674074590206\n",
      "loss iteration ->  3555 0.08065012097358704\n",
      "loss iteration ->  3560 0.03705955296754837\n",
      "loss iteration ->  3565 0.3851337134838104\n",
      "loss iteration ->  3570 0.16099224984645844\n",
      "loss iteration ->  3575 0.1841767579317093\n",
      "loss iteration ->  3580 0.20751160383224487\n",
      "loss iteration ->  3585 0.15046775341033936\n",
      "loss iteration ->  3590 0.14639241993427277\n",
      "loss iteration ->  3595 0.06879173964262009\n",
      "loss iteration ->  3600 0.16585269570350647\n",
      "loss iteration ->  3605 0.06905003637075424\n",
      "loss iteration ->  3610 0.07905162125825882\n",
      "loss iteration ->  3615 0.02205006778240204\n",
      "loss iteration ->  3620 0.09326545894145966\n",
      "loss iteration ->  3625 0.19103077054023743\n",
      "loss iteration ->  3630 0.16647174954414368\n",
      "loss iteration ->  3635 0.12141244858503342\n",
      "loss iteration ->  3640 0.19122615456581116\n",
      "loss iteration ->  3645 0.20819170773029327\n",
      "loss iteration ->  3650 0.08940086513757706\n",
      "loss iteration ->  3655 0.1317734569311142\n",
      "loss iteration ->  3660 0.07385829836130142\n",
      "loss iteration ->  3665 0.10750222951173782\n",
      "loss iteration ->  3670 0.15422146022319794\n",
      "loss iteration ->  3675 0.21463625133037567\n",
      "loss iteration ->  3680 0.04155333712697029\n",
      "loss iteration ->  3685 0.13508042693138123\n",
      "loss iteration ->  3690 0.1267286092042923\n",
      "loss iteration ->  3695 0.07240332663059235\n",
      "loss iteration ->  3700 0.08022736757993698\n",
      "loss iteration ->  3705 0.02645702287554741\n",
      "loss iteration ->  3710 0.19340187311172485\n",
      "loss iteration ->  3715 0.08460152894258499\n",
      "loss iteration ->  3720 0.11670858412981033\n",
      "loss iteration ->  3725 0.0919015184044838\n",
      "loss iteration ->  3730 0.1037086620926857\n",
      "loss iteration ->  3735 0.35954898595809937\n",
      "loss iteration ->  3740 0.16008521616458893\n",
      "loss iteration ->  3745 0.1442522555589676\n",
      "loss iteration ->  3750 0.04235312342643738\n",
      "loss iteration ->  3755 0.11385895311832428\n",
      "loss iteration ->  3760 0.3110198378562927\n",
      "loss iteration ->  3765 0.050223641097545624\n",
      "loss iteration ->  3770 0.052060309797525406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  3775 0.05398242920637131\n",
      "loss iteration ->  3780 0.13315574824810028\n",
      "loss iteration ->  3785 0.06449830532073975\n",
      "loss iteration ->  3790 0.06152352690696716\n",
      "loss iteration ->  3795 0.14320477843284607\n",
      "loss iteration ->  3800 0.04634175822138786\n",
      "loss iteration ->  3805 0.04890846833586693\n",
      "loss iteration ->  3810 0.15524977445602417\n",
      "loss iteration ->  3815 0.09578672051429749\n",
      "loss iteration ->  3820 0.27156519889831543\n",
      "loss iteration ->  3825 0.1782999485731125\n",
      "loss iteration ->  3830 0.20049814879894257\n",
      "loss iteration ->  3835 0.07894110679626465\n",
      "loss iteration ->  3840 0.15200692415237427\n",
      "loss iteration ->  3845 0.07593519985675812\n",
      "loss iteration ->  3850 0.1653614342212677\n",
      "loss iteration ->  3855 0.06058483198285103\n",
      "loss iteration ->  3860 0.06082502380013466\n",
      "loss iteration ->  3865 0.05595611035823822\n",
      "loss iteration ->  3870 0.13828428089618683\n",
      "loss iteration ->  3875 0.04111397638916969\n",
      "loss iteration ->  3880 0.10100235044956207\n",
      "loss iteration ->  3885 0.14021894335746765\n",
      "loss iteration ->  3890 0.11591236293315887\n",
      "loss iteration ->  3895 0.05036592483520508\n",
      "loss iteration ->  3900 0.1489749699831009\n",
      "loss iteration ->  3905 0.35962194204330444\n",
      "loss iteration ->  3910 0.09729102998971939\n",
      "loss iteration ->  3915 0.38580888509750366\n",
      "loss iteration ->  3920 0.279086172580719\n",
      "loss iteration ->  3925 0.18564370274543762\n",
      "loss iteration ->  3930 0.1642429381608963\n",
      "loss iteration ->  3935 0.20319893956184387\n",
      "loss iteration ->  3940 0.3012145161628723\n",
      "loss iteration ->  3945 0.1555490493774414\n",
      "loss iteration ->  3950 0.04457469284534454\n",
      "loss iteration ->  3955 0.12464901804924011\n",
      "loss iteration ->  3960 0.14698588848114014\n",
      "loss iteration ->  3965 0.2028566598892212\n",
      "loss iteration ->  3970 0.12789928913116455\n",
      "loss iteration ->  3975 0.06833668798208237\n",
      "loss iteration ->  3980 0.037341222167015076\n",
      "loss iteration ->  3985 0.21251489222049713\n",
      "loss iteration ->  3990 0.27441227436065674\n",
      "loss iteration ->  3995 0.08099927008152008\n",
      "loss iteration ->  4000 0.12531399726867676\n",
      "loss iteration ->  4005 0.11152899265289307\n",
      "loss iteration ->  4010 0.03384970873594284\n",
      "loss iteration ->  4015 0.22506047785282135\n",
      "loss iteration ->  4020 0.32633376121520996\n",
      "loss iteration ->  4025 0.10543176531791687\n",
      "loss iteration ->  4030 0.06115053966641426\n",
      "loss iteration ->  4035 0.05240856856107712\n",
      "loss iteration ->  4040 0.09883809834718704\n",
      "loss iteration ->  4045 0.12338461726903915\n",
      "loss iteration ->  4050 0.09087187051773071\n",
      "loss iteration ->  4055 0.2622999846935272\n",
      "loss iteration ->  4060 0.07359329611063004\n",
      "loss iteration ->  4065 0.05801320821046829\n",
      "loss iteration ->  4070 0.08088308572769165\n",
      "loss iteration ->  4075 0.055206358432769775\n",
      "loss iteration ->  4080 0.07803061604499817\n",
      "loss iteration ->  4085 0.3242180347442627\n",
      "loss iteration ->  4090 0.0852440595626831\n",
      "loss iteration ->  4095 0.14132435619831085\n",
      "loss iteration ->  4100 0.09673936665058136\n",
      "loss iteration ->  4105 0.20255489647388458\n",
      "loss iteration ->  4110 0.04060276225209236\n",
      "loss iteration ->  4115 0.1885034441947937\n",
      "loss iteration ->  4120 0.18618911504745483\n",
      "loss iteration ->  4125 0.11692903935909271\n",
      "loss iteration ->  4130 0.05035444349050522\n",
      "loss iteration ->  4135 0.0977846309542656\n",
      "loss iteration ->  4140 0.17755642533302307\n",
      "loss iteration ->  4145 0.18806855380535126\n",
      "loss iteration ->  4150 0.21331967413425446\n",
      "loss iteration ->  4155 0.03836795315146446\n",
      "loss iteration ->  4160 0.10932232439517975\n",
      "loss iteration ->  4165 0.059582751244306564\n",
      "loss iteration ->  4170 0.036746248602867126\n",
      "loss iteration ->  4175 0.30048277974128723\n",
      "loss iteration ->  4180 0.13053525984287262\n",
      "loss iteration ->  4185 0.10216385126113892\n",
      "loss iteration ->  4190 0.1220589280128479\n",
      "loss iteration ->  4195 0.02541983686387539\n",
      "loss iteration ->  4200 0.05639566108584404\n",
      "loss iteration ->  4205 0.033674564212560654\n",
      "loss iteration ->  4210 0.054422054439783096\n",
      "loss iteration ->  4215 0.05049993842840195\n",
      "loss iteration ->  4220 0.04475906863808632\n",
      "loss iteration ->  4225 0.07521354407072067\n",
      "loss iteration ->  4230 0.20202422142028809\n",
      "loss iteration ->  4235 0.4343680143356323\n",
      "loss iteration ->  4240 0.08135073632001877\n",
      "loss iteration ->  4245 0.03821098804473877\n",
      "loss iteration ->  4250 0.2506503760814667\n",
      "loss iteration ->  4255 0.14670804142951965\n",
      "loss iteration ->  4260 0.13912354409694672\n",
      "loss iteration ->  4265 0.08857403695583344\n",
      "loss iteration ->  4270 0.04497550427913666\n",
      "loss iteration ->  4275 0.19425950944423676\n",
      "loss iteration ->  4280 0.09398387372493744\n",
      "loss iteration ->  4285 0.1109817773103714\n",
      "loss iteration ->  4290 0.06340980529785156\n",
      "loss iteration ->  4295 0.06304829567670822\n",
      "loss iteration ->  4300 0.03366638347506523\n",
      "loss iteration ->  4305 0.1010960265994072\n",
      "loss iteration ->  4310 0.08527016639709473\n",
      "loss iteration ->  4315 0.07661373168230057\n",
      "loss iteration ->  4320 0.11140553653240204\n",
      "loss iteration ->  4325 0.12555097043514252\n",
      "loss iteration ->  4330 0.12554708123207092\n",
      "loss iteration ->  4335 0.046067409217357635\n",
      "loss iteration ->  4340 0.010549071244895458\n",
      "loss iteration ->  4345 0.13474823534488678\n",
      "loss iteration ->  4350 0.06549666821956635\n",
      "loss iteration ->  4355 0.06768953055143356\n",
      "loss iteration ->  4360 0.07480403780937195\n",
      "loss iteration ->  4365 0.05970866233110428\n",
      "loss iteration ->  4370 0.057487063109874725\n",
      "loss iteration ->  4375 0.23340898752212524\n",
      "loss iteration ->  4380 0.041158899664878845\n",
      "loss iteration ->  4385 0.057439032942056656\n",
      "loss iteration ->  4390 0.21215683221817017\n",
      "loss iteration ->  4395 0.23519673943519592\n",
      "loss iteration ->  4400 0.19144582748413086\n",
      "loss iteration ->  4405 0.18219977617263794\n",
      "loss iteration ->  4410 0.10693154484033585\n",
      "loss iteration ->  4415 0.23993390798568726\n",
      "loss iteration ->  4420 0.12462921440601349\n",
      "loss iteration ->  4425 0.07691042125225067\n",
      "loss iteration ->  4430 0.1622384786605835\n",
      "loss iteration ->  4435 0.1267186403274536\n",
      "loss iteration ->  4440 0.10213039815425873\n",
      "loss iteration ->  4445 0.06680639833211899\n",
      "loss iteration ->  4450 0.04098684340715408\n",
      "loss iteration ->  4455 0.07237886637449265\n",
      "loss iteration ->  4460 0.05686391890048981\n",
      "loss iteration ->  4465 0.28484994173049927\n",
      "loss iteration ->  4470 0.12128671258687973\n",
      "loss iteration ->  4475 0.06197514757514\n",
      "loss iteration ->  4480 0.0656294897198677\n",
      "loss iteration ->  4485 0.11265512555837631\n",
      "loss iteration ->  4490 0.3146483600139618\n",
      "loss iteration ->  4495 0.03746414929628372\n",
      "loss iteration ->  4500 0.06531542539596558\n",
      "loss iteration ->  4505 0.08355636894702911\n",
      "loss iteration ->  4510 0.07826657593250275\n",
      "loss iteration ->  4515 0.2809169292449951\n",
      "loss iteration ->  4520 0.3157842457294464\n",
      "loss iteration ->  4525 0.09051715582609177\n",
      "loss iteration ->  4530 0.10686106979846954\n",
      "loss iteration ->  4535 0.2765660881996155\n",
      "loss iteration ->  4540 0.434344619512558\n",
      "loss iteration ->  4545 0.3895529508590698\n",
      "loss iteration ->  4550 0.07674570381641388\n",
      "loss iteration ->  4555 0.07003729045391083\n",
      "loss iteration ->  4560 0.12187167257070541\n",
      "loss iteration ->  4565 0.126249298453331\n",
      "loss iteration ->  4570 0.2513657212257385\n",
      "loss iteration ->  4575 0.09863414615392685\n",
      "loss iteration ->  4580 0.09721964597702026\n",
      "loss iteration ->  4585 0.14513538777828217\n",
      "loss iteration ->  4590 0.043944232165813446\n",
      "loss iteration ->  4595 0.07010123878717422\n",
      "loss iteration ->  4600 0.0718243420124054\n",
      "loss iteration ->  4605 0.046290360391139984\n",
      "loss iteration ->  4610 0.2543773651123047\n",
      "loss iteration ->  4615 0.03536297753453255\n",
      "loss iteration ->  4620 0.0998087003827095\n",
      "loss iteration ->  4625 0.15500369668006897\n",
      "loss iteration ->  4630 0.12617328763008118\n",
      "loss iteration ->  4635 0.13401249051094055\n",
      "loss iteration ->  4640 0.03246701508760452\n",
      "loss iteration ->  4645 0.1807384490966797\n",
      "loss iteration ->  4650 0.0667620524764061\n",
      "loss iteration ->  4655 0.16203846037387848\n",
      "loss iteration ->  4660 0.09163935482501984\n",
      "loss iteration ->  4665 0.12000873684883118\n",
      "loss iteration ->  4670 0.12790197134017944\n",
      "loss iteration ->  4675 0.16744758188724518\n",
      "loss iteration ->  4680 0.1609310507774353\n",
      "loss iteration ->  4685 0.1896113008260727\n",
      "loss iteration ->  4690 0.03524607792496681\n",
      "loss iteration ->  4695 0.07285235822200775\n",
      "loss iteration ->  4700 0.16348321735858917\n",
      "loss iteration ->  4705 0.34845784306526184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  4710 0.23838697373867035\n",
      "loss iteration ->  4715 0.10199267417192459\n",
      "loss iteration ->  4720 0.023828059434890747\n",
      "loss iteration ->  4725 0.037112992256879807\n",
      "loss iteration ->  4730 0.1763581484556198\n",
      "loss iteration ->  4735 0.1264694482088089\n",
      "loss iteration ->  4740 0.23458276689052582\n",
      "loss iteration ->  4745 0.0856214165687561\n",
      "loss iteration ->  4750 0.05894636735320091\n",
      "loss iteration ->  4755 0.25510600209236145\n",
      "loss iteration ->  4760 0.20789143443107605\n",
      "loss iteration ->  4765 0.2423495203256607\n",
      "loss iteration ->  4770 0.09073301404714584\n",
      "loss iteration ->  4775 0.18259383738040924\n",
      "loss iteration ->  4780 0.09866020828485489\n",
      "loss iteration ->  4785 0.10583851486444473\n",
      "loss iteration ->  4790 0.16628190875053406\n",
      "loss iteration ->  4795 0.31669023633003235\n",
      "loss iteration ->  4800 0.04708659276366234\n",
      "loss iteration ->  4805 0.09630530327558517\n",
      "loss iteration ->  4810 0.11624038219451904\n",
      "loss iteration ->  4815 0.12960422039031982\n",
      "loss iteration ->  4820 0.17490103840827942\n",
      "loss iteration ->  4825 0.07593327015638351\n",
      "loss iteration ->  4830 0.11667212098836899\n",
      "loss iteration ->  4835 0.09546130895614624\n",
      "loss iteration ->  4840 0.24670974910259247\n",
      "loss iteration ->  4845 0.06659073382616043\n",
      "loss iteration ->  4850 0.1827615201473236\n",
      "loss iteration ->  4855 0.1572631597518921\n",
      "loss iteration ->  4860 0.058203767985105515\n",
      "loss iteration ->  4865 0.06856236606836319\n",
      "loss iteration ->  4870 0.07089127600193024\n",
      "loss iteration ->  4875 0.0803111121058464\n",
      "loss iteration ->  4880 0.08047933131456375\n",
      "loss iteration ->  4885 0.0923970565199852\n",
      "loss iteration ->  4890 0.03973229229450226\n",
      "loss iteration ->  4895 0.0398353710770607\n",
      "loss iteration ->  4900 0.10734821856021881\n",
      "loss iteration ->  4905 0.06166953593492508\n",
      "loss iteration ->  4910 0.04705986753106117\n",
      "loss iteration ->  4915 0.11674179881811142\n",
      "loss iteration ->  4920 0.1356867253780365\n",
      "loss iteration ->  4925 0.015838313847780228\n",
      "loss iteration ->  4930 0.06452108919620514\n",
      "loss iteration ->  4935 0.12502630054950714\n",
      "loss iteration ->  4940 0.09482608735561371\n",
      "loss iteration ->  4945 0.24550621211528778\n",
      "loss iteration ->  4950 0.12561434507369995\n",
      "loss iteration ->  4955 0.052725404500961304\n",
      "loss iteration ->  4960 0.06581788510084152\n",
      "loss iteration ->  4965 0.28135359287261963\n",
      "loss iteration ->  4970 0.25200140476226807\n",
      "loss iteration ->  4975 0.04727744683623314\n",
      "loss iteration ->  4980 0.04604869708418846\n",
      "loss iteration ->  4985 0.049549076706171036\n",
      "loss iteration ->  4990 0.1797574758529663\n",
      "loss iteration ->  4995 0.05616623908281326\n",
      "loss iteration ->  5000 0.4716644287109375\n",
      "loss iteration ->  5005 0.1487722396850586\n",
      "loss iteration ->  5010 0.028739579021930695\n",
      "loss iteration ->  5015 0.020135637372732162\n",
      "loss iteration ->  5020 0.3008725345134735\n",
      "loss iteration ->  5025 0.17965450882911682\n",
      "loss iteration ->  5030 0.1619761437177658\n",
      "loss iteration ->  5035 0.07416022568941116\n",
      "loss iteration ->  5040 0.09209921956062317\n",
      "loss iteration ->  5045 0.20821842551231384\n",
      "loss iteration ->  5050 0.04838542267680168\n",
      "loss iteration ->  5055 0.1288500279188156\n",
      "loss iteration ->  5060 0.01993582770228386\n",
      "loss iteration ->  5065 0.057736873626708984\n",
      "loss iteration ->  5070 0.23860062658786774\n",
      "loss iteration ->  5075 0.07698573172092438\n",
      "loss iteration ->  5080 0.09139956533908844\n",
      "loss iteration ->  5085 0.09178387373685837\n",
      "loss iteration ->  5090 0.08822043985128403\n",
      "loss iteration ->  5095 0.2227175235748291\n",
      "loss iteration ->  5100 0.24061983823776245\n",
      "loss iteration ->  5105 0.05562568083405495\n",
      "loss iteration ->  5110 0.08713522553443909\n",
      "loss iteration ->  5115 0.24591897428035736\n",
      "loss iteration ->  5120 0.08140607923269272\n",
      "loss iteration ->  5125 0.1599934697151184\n",
      "loss iteration ->  5130 0.07820271700620651\n",
      "loss iteration ->  5135 0.16706816852092743\n",
      "loss iteration ->  5140 0.15871797502040863\n",
      "loss iteration ->  5145 0.055411793291568756\n",
      "loss iteration ->  5150 0.09011866897344589\n",
      "loss iteration ->  5155 0.17943859100341797\n",
      "loss iteration ->  5160 0.06106381490826607\n",
      "loss iteration ->  5165 0.14396755397319794\n",
      "loss iteration ->  5170 0.15216130018234253\n",
      "loss iteration ->  5175 0.07152406126260757\n",
      "loss iteration ->  5180 0.10865885764360428\n",
      "loss iteration ->  5185 0.0659160315990448\n",
      "loss iteration ->  5190 0.1890915334224701\n",
      "loss iteration ->  5195 0.0701633021235466\n",
      "loss iteration ->  5200 0.13824094831943512\n",
      "loss iteration ->  5205 0.04105917736887932\n",
      "loss iteration ->  5210 0.1281578540802002\n",
      "loss iteration ->  5215 0.09106464684009552\n",
      "loss iteration ->  5220 0.1330188810825348\n",
      "loss iteration ->  5225 0.051131922751665115\n",
      "loss iteration ->  5230 0.05031166225671768\n",
      "loss iteration ->  5235 0.14148233830928802\n",
      "loss iteration ->  5240 0.13668328523635864\n",
      "loss iteration ->  5245 0.1165425106883049\n",
      "loss iteration ->  5250 0.07007673382759094\n",
      "loss iteration ->  5255 0.1763622760772705\n",
      "loss iteration ->  5260 0.3203802704811096\n",
      "loss iteration ->  5265 0.08987395465373993\n",
      "loss iteration ->  5270 0.04369830712676048\n",
      "loss iteration ->  5275 0.12735703587532043\n",
      "loss iteration ->  5280 0.11359303444623947\n",
      "loss iteration ->  5285 0.06895402818918228\n",
      "loss iteration ->  5290 0.09780809283256531\n",
      "loss iteration ->  5295 0.1600174456834793\n",
      "loss iteration ->  5300 0.11162939667701721\n",
      "loss iteration ->  5305 0.15365171432495117\n",
      "loss iteration ->  5310 0.10058993846178055\n",
      "loss iteration ->  5315 0.046251483261585236\n",
      "loss iteration ->  5320 0.06192157045006752\n",
      "loss iteration ->  5325 0.12927374243736267\n",
      "loss iteration ->  5330 0.06281682848930359\n",
      "loss iteration ->  5335 0.14178547263145447\n",
      "loss iteration ->  5340 0.10106910765171051\n",
      "loss iteration ->  5345 0.15441498160362244\n",
      "loss iteration ->  5350 0.2088114619255066\n",
      "loss iteration ->  5355 0.07533583790063858\n",
      "loss iteration ->  5360 0.09226507693529129\n",
      "loss iteration ->  5365 0.02300233393907547\n",
      "loss iteration ->  5370 0.16410262882709503\n",
      "loss iteration ->  5375 0.18756930530071259\n",
      "loss iteration ->  5380 0.053875576704740524\n",
      "loss iteration ->  5385 0.05726700648665428\n",
      "loss iteration ->  5390 0.10200558602809906\n",
      "loss iteration ->  5395 0.04975539445877075\n",
      "loss iteration ->  5400 0.16178752481937408\n",
      "loss iteration ->  5405 0.02848135121166706\n",
      "loss iteration ->  5410 0.10085311532020569\n",
      "loss iteration ->  5415 0.06706686317920685\n",
      "loss iteration ->  5420 0.034492168575525284\n",
      "loss iteration ->  5425 0.10088372975587845\n",
      "loss iteration ->  5430 0.04569298401474953\n",
      "loss iteration ->  5435 0.28126025199890137\n",
      "loss iteration ->  5440 0.024792160838842392\n",
      "loss iteration ->  5445 0.08452822268009186\n",
      "loss iteration ->  5450 0.08192788809537888\n",
      "loss iteration ->  5455 0.05313670635223389\n",
      "loss iteration ->  5460 0.08170399069786072\n",
      "loss iteration ->  5465 0.11474137008190155\n",
      "loss iteration ->  5470 0.3011249601840973\n",
      "loss iteration ->  5475 0.17431917786598206\n",
      "loss iteration ->  5480 0.2177973836660385\n",
      "loss iteration ->  5485 0.07206965237855911\n",
      "loss iteration ->  5490 0.07211588323116302\n",
      "loss iteration ->  5495 0.05177730694413185\n",
      "loss iteration ->  5500 0.238370880484581\n",
      "loss iteration ->  5505 0.2084842473268509\n",
      "loss iteration ->  5510 0.12081535905599594\n",
      "loss iteration ->  5515 0.0552372932434082\n",
      "loss iteration ->  5520 0.1722964644432068\n",
      "loss iteration ->  5525 0.20720241963863373\n",
      "loss iteration ->  5530 0.1221553236246109\n",
      "loss iteration ->  5535 0.05109945684671402\n",
      "loss iteration ->  5540 0.0717291533946991\n",
      "loss iteration ->  5545 0.021140195429325104\n",
      "loss iteration ->  5550 0.20258140563964844\n",
      "loss iteration ->  5555 0.5067315697669983\n",
      "loss iteration ->  5560 0.08248576521873474\n",
      "loss iteration ->  5565 0.13661721348762512\n",
      "loss iteration ->  5570 0.112320676445961\n",
      "loss iteration ->  5575 0.2445143461227417\n",
      "loss iteration ->  5580 0.16810397803783417\n",
      "loss iteration ->  5585 0.18551349639892578\n",
      "loss iteration ->  5590 0.20873583853244781\n",
      "loss iteration ->  5595 0.023036247119307518\n",
      "loss iteration ->  5600 0.07902051508426666\n",
      "loss iteration ->  5605 0.16299138963222504\n",
      "loss iteration ->  5610 0.15736381709575653\n",
      "loss iteration ->  5615 0.13227233290672302\n",
      "loss iteration ->  5620 0.05353343486785889\n",
      "loss iteration ->  5625 0.09456703811883926\n",
      "loss iteration ->  5630 0.12839335203170776\n",
      "loss iteration ->  5635 0.12344617396593094\n",
      "loss iteration ->  5640 0.14444203674793243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  5645 0.1864696741104126\n",
      "loss iteration ->  5650 0.20530781149864197\n",
      "loss iteration ->  5655 0.09363196790218353\n",
      "loss iteration ->  5660 0.1366916298866272\n",
      "loss iteration ->  5665 0.26009970903396606\n",
      "loss iteration ->  5670 0.07156100124120712\n",
      "loss iteration ->  5675 0.0814736932516098\n",
      "loss iteration ->  5680 0.14200907945632935\n",
      "loss iteration ->  5685 0.06733085215091705\n",
      "loss iteration ->  5690 0.029764443635940552\n",
      "loss iteration ->  5695 0.23413510620594025\n",
      "loss iteration ->  5700 0.24254556000232697\n",
      "loss iteration ->  5705 0.0919015109539032\n",
      "loss iteration ->  5710 0.022085700184106827\n",
      "loss iteration ->  5715 0.1306351125240326\n",
      "loss iteration ->  5720 0.07099751383066177\n",
      "loss iteration ->  5725 0.1022028774023056\n",
      "loss iteration ->  5730 0.09378723055124283\n",
      "loss iteration ->  5735 0.04591953009366989\n",
      "loss iteration ->  5740 0.12408434599637985\n",
      "loss iteration ->  5745 0.027167340740561485\n",
      "loss iteration ->  5750 0.040782175958156586\n",
      "loss iteration ->  5755 0.11791527271270752\n",
      "loss iteration ->  5760 0.09468109160661697\n",
      "loss iteration ->  5765 0.30897828936576843\n",
      "loss iteration ->  5770 0.11105725169181824\n",
      "loss iteration ->  5775 0.21902084350585938\n",
      "loss iteration ->  5780 0.05900508910417557\n",
      "loss iteration ->  5785 0.1552775800228119\n",
      "loss iteration ->  5790 0.02386602573096752\n",
      "loss iteration ->  5795 0.07854190468788147\n",
      "loss iteration ->  5800 0.05017685145139694\n",
      "loss iteration ->  5805 0.03376583755016327\n",
      "loss iteration ->  5810 0.018162982538342476\n",
      "loss iteration ->  5815 0.0857296735048294\n",
      "loss iteration ->  5820 0.0318756178021431\n",
      "loss iteration ->  5825 0.08028311282396317\n",
      "loss iteration ->  5830 0.1516326665878296\n",
      "loss iteration ->  5835 0.06924214959144592\n",
      "loss iteration ->  5840 0.17987821996212006\n",
      "loss iteration ->  5845 0.1631760597229004\n",
      "loss iteration ->  5850 0.13952864706516266\n",
      "loss iteration ->  5855 0.0599835067987442\n",
      "loss iteration ->  5860 0.10278509557247162\n",
      "loss iteration ->  5865 0.1120249554514885\n",
      "loss iteration ->  5870 0.0456094816327095\n",
      "loss iteration ->  5875 0.12700480222702026\n",
      "loss iteration ->  5880 0.05352308228611946\n",
      "loss iteration ->  5885 0.12939639389514923\n",
      "loss iteration ->  5890 0.17753885686397552\n",
      "loss iteration ->  5895 0.0892302617430687\n",
      "loss iteration ->  5900 0.3468254804611206\n",
      "loss iteration ->  5905 0.10724024474620819\n",
      "loss iteration ->  5910 0.2767716944217682\n",
      "loss iteration ->  5915 0.1466025412082672\n",
      "loss iteration ->  5920 0.10911455750465393\n",
      "loss iteration ->  5925 0.06877243518829346\n",
      "loss iteration ->  5930 0.056919652968645096\n",
      "loss iteration ->  5935 0.05475639924407005\n",
      "loss iteration ->  5940 0.10182320326566696\n",
      "loss iteration ->  5945 0.030872544273734093\n",
      "loss iteration ->  5950 0.1520124226808548\n",
      "loss iteration ->  5955 0.050886403769254684\n",
      "loss iteration ->  5960 0.16569840908050537\n",
      "loss iteration ->  5965 0.05870762839913368\n",
      "loss iteration ->  5970 0.17876647412776947\n",
      "loss iteration ->  5975 0.17019487917423248\n",
      "loss iteration ->  5980 0.03742536902427673\n",
      "loss iteration ->  5985 0.08370006829500198\n",
      "loss iteration ->  5990 0.09509338438510895\n",
      "loss iteration ->  5995 0.0617779940366745\n",
      "loss iteration ->  6000 0.042204249650239944\n",
      "loss iteration ->  6005 0.1478075534105301\n",
      "loss iteration ->  6010 0.15836314857006073\n",
      "loss iteration ->  6015 0.2782881259918213\n",
      "loss iteration ->  6020 0.04731602966785431\n",
      "loss iteration ->  6025 0.0671386867761612\n",
      "loss iteration ->  6030 0.042147330939769745\n",
      "loss iteration ->  6035 0.0464477501809597\n",
      "loss iteration ->  6040 0.01988060586154461\n",
      "loss iteration ->  6045 0.08742896467447281\n",
      "loss iteration ->  6050 0.21230244636535645\n",
      "loss iteration ->  6055 0.05548781901597977\n",
      "loss iteration ->  6060 0.15912842750549316\n",
      "loss iteration ->  6065 0.025489959865808487\n",
      "loss iteration ->  6070 0.07017289847135544\n",
      "loss iteration ->  6075 0.2246684730052948\n",
      "loss iteration ->  6080 0.09599104523658752\n",
      "loss iteration ->  6085 0.14959806203842163\n",
      "loss iteration ->  6090 0.1019575297832489\n",
      "loss iteration ->  6095 0.10040394961833954\n",
      "loss iteration ->  6100 0.10224965959787369\n",
      "loss iteration ->  6105 0.14692090451717377\n",
      "loss iteration ->  6110 0.15338212251663208\n",
      "loss iteration ->  6115 0.040473755449056625\n",
      "loss iteration ->  6120 0.022513020783662796\n",
      "loss iteration ->  6125 0.12423282861709595\n",
      "loss iteration ->  6130 0.11264924705028534\n",
      "loss iteration ->  6135 0.16533291339874268\n",
      "loss iteration ->  6140 0.06527009606361389\n",
      "loss iteration ->  6145 0.056898415088653564\n",
      "loss iteration ->  6150 0.068053238093853\n",
      "loss iteration ->  6155 0.1820734143257141\n",
      "loss iteration ->  6160 0.15118753910064697\n",
      "loss iteration ->  6165 0.05964026227593422\n",
      "loss iteration ->  6170 0.3318825364112854\n",
      "loss iteration ->  6175 0.16364577412605286\n",
      "loss iteration ->  6180 0.07470128685235977\n",
      "loss iteration ->  6185 0.03926292434334755\n",
      "loss iteration ->  6190 0.26182425022125244\n",
      "loss iteration ->  6195 0.09937349706888199\n",
      "loss iteration ->  6200 0.06539001315832138\n",
      "loss iteration ->  6205 0.22744111716747284\n",
      "loss iteration ->  6210 0.10564093291759491\n",
      "loss iteration ->  6215 0.051251545548439026\n",
      "loss iteration ->  6220 0.10410192608833313\n",
      "loss iteration ->  6225 0.23668548464775085\n",
      "loss iteration ->  6230 0.16654662787914276\n",
      "loss iteration ->  6235 0.04958125203847885\n",
      "loss iteration ->  6240 0.45993736386299133\n",
      "loss iteration ->  6245 0.14021271467208862\n",
      "loss iteration ->  6250 0.09454116970300674\n",
      "loss iteration ->  6255 0.04548272863030434\n",
      "loss iteration ->  6260 0.08530145138502121\n",
      "loss iteration ->  6265 0.0806526467204094\n",
      "loss iteration ->  6270 0.09929361194372177\n",
      "loss iteration ->  6275 0.08226785063743591\n",
      "loss iteration ->  6280 0.06345720589160919\n",
      "loss iteration ->  6285 0.03055664524435997\n",
      "loss iteration ->  6290 0.05502082407474518\n",
      "loss iteration ->  6295 0.23181748390197754\n",
      "loss iteration ->  6300 0.07462531328201294\n",
      "loss iteration ->  6305 0.06858517974615097\n",
      "loss iteration ->  6310 0.05379066243767738\n",
      "loss iteration ->  6315 0.0718042328953743\n",
      "loss iteration ->  6320 0.07310202717781067\n",
      "loss iteration ->  6325 0.022094782441854477\n",
      "loss iteration ->  6330 0.16130408644676208\n",
      "loss iteration ->  6335 0.13127566874027252\n",
      "loss iteration ->  6340 0.1090436577796936\n",
      "loss iteration ->  6345 0.0734264999628067\n",
      "loss iteration ->  6350 0.04586503282189369\n",
      "loss iteration ->  6355 0.27822425961494446\n",
      "loss iteration ->  6360 0.14695501327514648\n",
      "loss iteration ->  6365 0.032211173325777054\n",
      "loss iteration ->  6370 0.1102532148361206\n",
      "loss iteration ->  6375 0.21368050575256348\n",
      "loss iteration ->  6380 0.06350335478782654\n",
      "loss iteration ->  6385 0.15413889288902283\n",
      "loss iteration ->  6390 0.3181590735912323\n",
      "loss iteration ->  6395 0.06384432315826416\n",
      "loss iteration ->  6400 0.035621728748083115\n",
      "loss iteration ->  6405 0.10396304726600647\n",
      "loss iteration ->  6410 0.13425849378108978\n",
      "loss iteration ->  6415 0.20264913141727448\n",
      "loss iteration ->  6420 0.11268264800310135\n",
      "loss iteration ->  6425 0.19502483308315277\n",
      "loss iteration ->  6430 0.013192614540457726\n",
      "loss iteration ->  6435 0.04527101293206215\n",
      "loss iteration ->  6440 0.20269204676151276\n",
      "loss iteration ->  6445 0.0784752145409584\n",
      "loss iteration ->  6450 0.07802463322877884\n",
      "loss iteration ->  6455 0.020244566723704338\n",
      "loss iteration ->  6460 0.0902453064918518\n",
      "loss iteration ->  6465 0.010495145805180073\n",
      "loss iteration ->  6470 0.1285904198884964\n",
      "loss iteration ->  6475 0.07836955040693283\n",
      "loss iteration ->  6480 0.1596541404724121\n",
      "loss iteration ->  6485 0.07701117545366287\n",
      "loss iteration ->  6490 0.09669970721006393\n",
      "loss iteration ->  6495 0.20251069962978363\n",
      "loss iteration ->  6500 0.10022446513175964\n",
      "loss iteration ->  6505 0.03505311533808708\n",
      "loss iteration ->  6510 0.0767124593257904\n",
      "loss iteration ->  6515 0.2174282968044281\n",
      "loss iteration ->  6520 0.06856344640254974\n",
      "loss iteration ->  6525 0.17898786067962646\n",
      "loss iteration ->  6530 0.06806092709302902\n",
      "loss iteration ->  6535 0.08776744455099106\n",
      "loss iteration ->  6540 0.3199167549610138\n",
      "loss iteration ->  6545 0.0590914748609066\n",
      "loss iteration ->  6550 0.048226311802864075\n",
      "loss iteration ->  6555 0.07189293205738068\n",
      "loss iteration ->  6560 0.06508442014455795\n",
      "loss iteration ->  6565 0.07971552014350891\n",
      "loss iteration ->  6570 0.17569813132286072\n",
      "loss iteration ->  6575 0.11341290175914764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  6580 0.09542369097471237\n",
      "loss iteration ->  6585 0.10086841881275177\n",
      "loss iteration ->  6590 0.08172443509101868\n",
      "loss iteration ->  6595 0.26958343386650085\n",
      "loss iteration ->  6600 0.01649501733481884\n",
      "loss iteration ->  6605 0.08552893996238708\n",
      "loss iteration ->  6610 0.14285975694656372\n",
      "loss iteration ->  6615 0.06990920007228851\n",
      "loss iteration ->  6620 0.13359545171260834\n",
      "loss iteration ->  6625 0.25411897897720337\n",
      "loss iteration ->  6630 0.13165993988513947\n",
      "loss iteration ->  6635 0.07496748864650726\n",
      "loss iteration ->  6640 0.07702013105154037\n",
      "loss iteration ->  6645 0.06144173443317413\n",
      "loss iteration ->  6650 0.08026310801506042\n",
      "loss iteration ->  6655 0.015629354864358902\n",
      "loss iteration ->  6660 0.09025871008634567\n",
      "loss iteration ->  6665 0.36426207423210144\n",
      "loss iteration ->  6670 0.4208802282810211\n",
      "loss iteration ->  6675 0.10986215621232986\n",
      "loss iteration ->  6680 0.06967071443796158\n",
      "loss iteration ->  6685 0.06749576330184937\n",
      "loss iteration ->  6690 0.07198731601238251\n",
      "loss iteration ->  6695 0.016590023413300514\n",
      "loss iteration ->  6700 0.3268269896507263\n",
      "loss iteration ->  6705 0.02213248796761036\n",
      "loss iteration ->  6710 0.07438938319683075\n",
      "loss iteration ->  6715 0.1340406835079193\n",
      "loss iteration ->  6720 0.06534622609615326\n",
      "loss iteration ->  6725 0.15939156711101532\n",
      "loss iteration ->  6730 0.13357725739479065\n",
      "loss iteration ->  6735 0.0535796582698822\n",
      "loss iteration ->  6740 0.11519430577754974\n",
      "loss iteration ->  6745 0.0717315748333931\n",
      "loss iteration ->  6750 0.02904096618294716\n",
      "loss iteration ->  6755 0.06738955527544022\n",
      "loss iteration ->  6760 0.0251010712236166\n",
      "loss iteration ->  6765 0.11467264592647552\n",
      "loss iteration ->  6770 0.043304745107889175\n",
      "loss iteration ->  6775 0.1695196032524109\n",
      "loss iteration ->  6780 0.027203138917684555\n",
      "loss iteration ->  6785 0.18291215598583221\n",
      "loss iteration ->  6790 0.13272492587566376\n",
      "loss iteration ->  6795 0.01380826998502016\n",
      "loss iteration ->  6800 0.046435121446847916\n",
      "loss iteration ->  6805 0.17182572185993195\n",
      "loss iteration ->  6810 0.054293032735586166\n",
      "loss iteration ->  6815 0.20495082437992096\n",
      "loss iteration ->  6820 0.0272607933729887\n",
      "loss iteration ->  6825 0.250203937292099\n",
      "loss iteration ->  6830 0.07683083415031433\n",
      "loss iteration ->  6835 0.1277233064174652\n",
      "loss iteration ->  6840 0.0541660375893116\n",
      "loss iteration ->  6845 0.1678011119365692\n",
      "loss iteration ->  6850 0.09097568690776825\n",
      "loss iteration ->  6855 0.056975025683641434\n",
      "loss iteration ->  6860 0.14834895730018616\n",
      "loss iteration ->  6865 0.045146603137254715\n",
      "loss iteration ->  6870 0.12119881063699722\n",
      "loss iteration ->  6875 0.08092406392097473\n",
      "loss iteration ->  6880 0.083055779337883\n",
      "loss iteration ->  6885 0.07406719774007797\n",
      "loss iteration ->  6890 0.04556022584438324\n",
      "loss iteration ->  6895 0.09021089971065521\n",
      "loss iteration ->  6900 0.05788073688745499\n",
      "loss iteration ->  6905 0.0604858472943306\n",
      "loss iteration ->  6910 0.19742633402347565\n",
      "loss iteration ->  6915 0.1427394151687622\n",
      "loss iteration ->  6920 0.04449033737182617\n",
      "loss iteration ->  6925 0.14159956574440002\n",
      "loss iteration ->  6930 0.14451760053634644\n",
      "loss iteration ->  6935 0.1032680869102478\n",
      "loss iteration ->  6940 0.05057401582598686\n",
      "loss iteration ->  6945 0.2529682219028473\n",
      "loss iteration ->  6950 0.006346373353153467\n",
      "loss iteration ->  6955 0.18037299811840057\n",
      "loss iteration ->  6960 0.06713499873876572\n",
      "loss iteration ->  6965 0.23063704371452332\n",
      "loss iteration ->  6970 0.11665182560682297\n",
      "loss iteration ->  6975 0.028379568830132484\n",
      "loss iteration ->  6980 0.10568556189537048\n",
      "loss iteration ->  6985 0.0560808889567852\n",
      "loss iteration ->  6990 0.04053420200943947\n",
      "loss iteration ->  6995 0.07970117032527924\n",
      "loss iteration ->  7000 0.18978840112686157\n",
      "loss iteration ->  7005 0.15532487630844116\n",
      "loss iteration ->  7010 0.08554159104824066\n",
      "loss iteration ->  7015 0.13758353888988495\n",
      "loss iteration ->  7020 0.05288371816277504\n",
      "loss iteration ->  7025 0.11759623885154724\n",
      "loss iteration ->  7030 0.06719886511564255\n",
      "loss iteration ->  7035 0.03396807610988617\n",
      "loss iteration ->  7040 0.053220078349113464\n",
      "loss iteration ->  7045 0.03862764313817024\n",
      "loss iteration ->  7050 0.16225799918174744\n",
      "loss iteration ->  7055 0.14510636031627655\n",
      "loss iteration ->  7060 0.0636860728263855\n",
      "loss iteration ->  7065 0.020185040310025215\n",
      "loss iteration ->  7070 0.025358907878398895\n",
      "loss iteration ->  7075 0.1330559104681015\n",
      "loss iteration ->  7080 0.09856870770454407\n",
      "loss iteration ->  7085 0.15899206697940826\n",
      "loss iteration ->  7090 0.1775425225496292\n",
      "loss iteration ->  7095 0.04973782226443291\n",
      "loss iteration ->  7100 0.08956295251846313\n",
      "loss iteration ->  7105 0.1416781097650528\n",
      "loss iteration ->  7110 0.19266915321350098\n",
      "loss iteration ->  7115 0.0633605495095253\n",
      "loss iteration ->  7120 0.10548914968967438\n",
      "loss iteration ->  7125 0.10348992049694061\n",
      "loss iteration ->  7130 0.025187816470861435\n",
      "loss iteration ->  7135 0.029830215498805046\n",
      "loss iteration ->  7140 0.16582992672920227\n",
      "loss iteration ->  7145 0.043938811868429184\n",
      "loss iteration ->  7150 0.09667101502418518\n",
      "loss iteration ->  7155 0.08723468333482742\n",
      "loss iteration ->  7160 0.06655233353376389\n",
      "loss iteration ->  7165 0.06738101691007614\n",
      "loss iteration ->  7170 0.02547289989888668\n",
      "loss iteration ->  7175 0.10412635654211044\n",
      "loss iteration ->  7180 0.04038276895880699\n",
      "loss iteration ->  7185 0.29068928956985474\n",
      "loss iteration ->  7190 0.13242977857589722\n",
      "loss iteration ->  7195 0.13159988820552826\n",
      "loss iteration ->  7200 0.38679227232933044\n",
      "loss iteration ->  7205 0.03356601297855377\n",
      "loss iteration ->  7210 0.03944280743598938\n",
      "loss iteration ->  7215 0.253868043422699\n",
      "loss iteration ->  7220 0.061024125665426254\n",
      "loss iteration ->  7225 0.12959469854831696\n",
      "loss iteration ->  7230 0.057534899562597275\n",
      "loss iteration ->  7235 0.13699740171432495\n",
      "loss iteration ->  7240 0.1406252682209015\n",
      "loss iteration ->  7245 0.1381724625825882\n",
      "loss iteration ->  7250 0.030815768986940384\n",
      "loss iteration ->  7255 0.11101400852203369\n",
      "loss iteration ->  7260 0.17247051000595093\n",
      "loss iteration ->  7265 0.09774751216173172\n",
      "loss iteration ->  7270 0.009482135996222496\n",
      "loss iteration ->  7275 0.07216520607471466\n",
      "loss iteration ->  7280 0.19825085997581482\n",
      "loss iteration ->  7285 0.06455212831497192\n",
      "loss iteration ->  7290 0.15518581867218018\n",
      "loss iteration ->  7295 0.10230869054794312\n",
      "loss iteration ->  7300 0.13376638293266296\n",
      "loss iteration ->  7305 0.03989090397953987\n",
      "loss iteration ->  7310 0.10819219797849655\n",
      "loss iteration ->  7315 0.07900559902191162\n",
      "loss iteration ->  7320 0.068008191883564\n",
      "loss iteration ->  7325 0.07481693476438522\n",
      "loss iteration ->  7330 0.060288023203611374\n",
      "loss iteration ->  7335 0.0829247385263443\n",
      "loss iteration ->  7340 0.042370982468128204\n",
      "loss iteration ->  7345 0.14743830263614655\n",
      "loss iteration ->  7350 0.188620463013649\n",
      "loss iteration ->  7355 0.10441958904266357\n",
      "loss iteration ->  7360 0.11493107676506042\n",
      "loss iteration ->  7365 0.11607329547405243\n",
      "loss iteration ->  7370 0.21398429572582245\n",
      "loss iteration ->  7375 0.1295449584722519\n",
      "loss iteration ->  7380 0.09231222420930862\n",
      "loss iteration ->  7385 0.06195805221796036\n",
      "loss iteration ->  7390 0.31094348430633545\n",
      "loss iteration ->  7395 0.4236867129802704\n",
      "loss iteration ->  7400 0.0463121123611927\n",
      "loss iteration ->  7405 0.05043027177453041\n",
      "loss iteration ->  7410 0.0336897112429142\n",
      "loss iteration ->  7415 0.11987753212451935\n",
      "loss iteration ->  7420 0.030135847628116608\n",
      "loss iteration ->  7425 0.0257057286798954\n",
      "loss iteration ->  7430 0.07397351413965225\n",
      "loss iteration ->  7435 0.08577871322631836\n",
      "loss iteration ->  7440 0.21260517835617065\n",
      "loss iteration ->  7445 0.07462485134601593\n",
      "loss iteration ->  7450 0.10578516125679016\n",
      "loss iteration ->  7455 0.18518301844596863\n",
      "loss iteration ->  7460 0.05679110437631607\n",
      "loss iteration ->  7465 0.0850374698638916\n",
      "loss iteration ->  7470 0.16651244461536407\n",
      "loss iteration ->  7475 0.053856123238801956\n",
      "loss iteration ->  7480 0.2675618529319763\n",
      "loss iteration ->  7485 0.08975698798894882\n",
      "loss iteration ->  7490 0.31098672747612\n",
      "loss iteration ->  7495 0.04128940775990486\n",
      "loss iteration ->  7500 0.09037606418132782\n",
      "loss iteration ->  7505 0.08529241383075714\n",
      "loss iteration ->  7510 0.29750412702560425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  7515 0.13101783394813538\n",
      "loss iteration ->  7520 0.04941582307219505\n",
      "loss iteration ->  7525 0.0344529002904892\n",
      "loss iteration ->  7530 0.030802415683865547\n",
      "loss iteration ->  7535 0.026996759697794914\n",
      "loss iteration ->  7540 0.10724771022796631\n",
      "loss iteration ->  7545 0.05009084939956665\n",
      "loss iteration ->  7550 0.26790282130241394\n",
      "loss iteration ->  7555 0.04886823147535324\n",
      "loss iteration ->  7560 0.038629576563835144\n",
      "loss iteration ->  7565 0.03303965926170349\n",
      "loss iteration ->  7570 0.03172940015792847\n",
      "loss iteration ->  7575 0.08770565688610077\n",
      "loss iteration ->  7580 0.08431969583034515\n",
      "loss iteration ->  7585 0.07696785032749176\n",
      "loss iteration ->  7590 0.1586330085992813\n",
      "loss iteration ->  7595 0.21259541809558868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pyuvraj/opt/anaconda3/lib/python3.9/site-packages/PIL/Image.py:3035: DecompressionBombWarning: Image size (143872000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  7600 0.1906307190656662\n",
      "loss iteration ->  7605 0.036511559039354324\n",
      "loss iteration ->  7610 0.17978452146053314\n",
      "loss iteration ->  7615 0.04934833571314812\n",
      "loss iteration ->  7620 0.04349154233932495\n",
      "loss iteration ->  7625 0.12104641646146774\n",
      "loss iteration ->  7630 0.11010488122701645\n",
      "loss iteration ->  7635 0.022673096507787704\n",
      "loss iteration ->  7640 0.11814815551042557\n",
      "loss iteration ->  7645 0.09683819860219955\n",
      "loss iteration ->  7650 0.1659368872642517\n",
      "loss iteration ->  7655 0.04458582028746605\n",
      "loss iteration ->  7660 0.08651543408632278\n",
      "loss iteration ->  7665 0.11621250212192535\n",
      "loss iteration ->  7670 0.15164493024349213\n",
      "loss iteration ->  7675 0.24689197540283203\n",
      "loss iteration ->  7680 0.06131646782159805\n",
      "loss iteration ->  7685 0.12784570455551147\n",
      "loss iteration ->  7690 0.05297398567199707\n",
      "loss iteration ->  7695 0.17311929166316986\n",
      "loss iteration ->  7700 0.2052941769361496\n",
      "loss iteration ->  7705 0.10608253628015518\n",
      "loss iteration ->  7710 0.04537717625498772\n",
      "loss iteration ->  7715 0.27767184376716614\n",
      "loss iteration ->  7720 0.08182070404291153\n",
      "loss iteration ->  7725 0.17193381488323212\n",
      "loss iteration ->  7730 0.08708862960338593\n",
      "loss iteration ->  7735 0.13504266738891602\n",
      "loss iteration ->  7740 0.14146342873573303\n",
      "loss iteration ->  7745 0.028864795342087746\n",
      "loss iteration ->  7750 0.15718090534210205\n",
      "loss iteration ->  7755 0.15717068314552307\n",
      "loss iteration ->  7760 0.03456081822514534\n",
      "loss iteration ->  7765 0.08220281451940536\n",
      "loss iteration ->  7770 0.023710574954748154\n",
      "loss iteration ->  7775 0.055741287767887115\n",
      "loss iteration ->  7780 0.2005518525838852\n",
      "loss iteration ->  7785 0.07279198616743088\n",
      "loss iteration ->  7790 0.11088299751281738\n",
      "loss iteration ->  7795 0.1765739619731903\n",
      "loss iteration ->  7800 0.047930438071489334\n",
      "loss iteration ->  7805 0.14733852446079254\n",
      "loss iteration ->  7810 0.12189401686191559\n",
      "loss iteration ->  7815 0.09692798554897308\n",
      "loss iteration ->  7820 0.2115170806646347\n",
      "loss iteration ->  7825 0.04010367393493652\n",
      "loss iteration ->  7830 0.0587368868291378\n",
      "loss iteration ->  7835 0.0770421102643013\n",
      "loss iteration ->  7840 0.07693116366863251\n",
      "loss iteration ->  7845 0.05465666949748993\n",
      "loss iteration ->  7850 0.07001891732215881\n",
      "loss iteration ->  7855 0.10001181066036224\n",
      "loss iteration ->  7860 0.02916036918759346\n",
      "loss iteration ->  7865 0.09783146530389786\n",
      "loss iteration ->  7870 0.10661030560731888\n",
      "loss iteration ->  7875 0.0453433096408844\n",
      "loss iteration ->  7880 0.1968090683221817\n",
      "loss iteration ->  7885 0.15114600956439972\n",
      "loss iteration ->  7890 0.07551773637533188\n",
      "loss iteration ->  7895 0.24229207634925842\n",
      "loss iteration ->  7900 0.17251037061214447\n",
      "loss iteration ->  7905 0.1748010367155075\n",
      "loss iteration ->  7910 0.2510361671447754\n",
      "loss iteration ->  7915 0.13341708481311798\n",
      "loss iteration ->  7920 0.3743705153465271\n",
      "loss iteration ->  7925 0.035656753927469254\n",
      "loss iteration ->  7930 0.024077508598566055\n",
      "loss iteration ->  7935 0.2308991402387619\n",
      "loss iteration ->  7940 0.03961946442723274\n",
      "loss iteration ->  7945 0.09609547257423401\n",
      "loss iteration ->  7950 0.14612329006195068\n",
      "loss iteration ->  7955 0.046644337475299835\n",
      "loss iteration ->  7960 0.11394286900758743\n",
      "loss iteration ->  7965 0.03766775131225586\n",
      "loss iteration ->  7970 0.05578967183828354\n",
      "loss iteration ->  7975 0.0657847672700882\n",
      "loss iteration ->  7980 0.03467839956283569\n",
      "loss iteration ->  7985 0.10767325013875961\n",
      "loss iteration ->  7990 0.03816048055887222\n",
      "loss iteration ->  7995 0.08395884931087494\n",
      "loss iteration ->  8000 0.15224340558052063\n",
      "loss iteration ->  8005 0.06961073726415634\n",
      "loss iteration ->  8010 0.11648688465356827\n",
      "loss iteration ->  8015 0.2976377308368683\n",
      "loss iteration ->  8020 0.2827242314815521\n",
      "loss iteration ->  8025 0.07754405587911606\n",
      "loss iteration ->  8030 0.1517992913722992\n",
      "loss iteration ->  8035 0.1447409987449646\n",
      "loss iteration ->  8040 0.10666894912719727\n",
      "loss iteration ->  8045 0.24162840843200684\n",
      "loss iteration ->  8050 0.10673059523105621\n",
      "loss iteration ->  8055 0.05317180976271629\n",
      "loss iteration ->  8060 0.3776879906654358\n",
      "loss iteration ->  8065 0.15133990347385406\n",
      "loss iteration ->  8070 0.112933449447155\n",
      "loss iteration ->  8075 0.15521569550037384\n",
      "loss iteration ->  8080 0.04482778161764145\n",
      "loss iteration ->  8085 0.038550734519958496\n",
      "loss iteration ->  8090 0.25208786129951477\n",
      "loss iteration ->  8095 0.12626385688781738\n",
      "loss iteration ->  8100 0.04322005808353424\n",
      "loss iteration ->  8105 0.041208602488040924\n",
      "loss iteration ->  8110 0.1479712426662445\n",
      "loss iteration ->  8115 0.16313451528549194\n",
      "loss iteration ->  8120 0.08711064606904984\n",
      "loss iteration ->  8125 0.13691219687461853\n",
      "loss iteration ->  8130 0.04646668583154678\n",
      "loss iteration ->  8135 0.0791722983121872\n",
      "loss iteration ->  8140 0.08936922252178192\n",
      "loss iteration ->  8145 0.10736414790153503\n",
      "loss iteration ->  8150 0.06575857102870941\n",
      "loss iteration ->  8155 0.13152089715003967\n",
      "loss iteration ->  8160 0.13855715095996857\n",
      "loss iteration ->  8165 0.1005886122584343\n",
      "loss iteration ->  8170 0.049890998750925064\n",
      "loss iteration ->  8175 0.09054157137870789\n",
      "loss iteration ->  8180 0.04777292162179947\n",
      "loss iteration ->  8185 0.06369278579950333\n",
      "loss iteration ->  8190 0.056108228862285614\n",
      "loss iteration ->  8195 0.0858478918671608\n",
      "loss iteration ->  8200 0.026996508240699768\n",
      "loss iteration ->  8205 0.04008353501558304\n",
      "loss iteration ->  8210 0.09368501603603363\n",
      "loss iteration ->  8215 0.1801759898662567\n",
      "loss iteration ->  8220 0.03675701096653938\n",
      "loss iteration ->  8225 0.07401756197214127\n",
      "loss iteration ->  8230 0.03430647403001785\n",
      "loss iteration ->  8235 0.2217206358909607\n",
      "loss iteration ->  8240 0.044642187654972076\n",
      "loss iteration ->  8245 0.3253041207790375\n",
      "loss iteration ->  8250 0.08730688691139221\n",
      "loss iteration ->  8255 0.04044152796268463\n",
      "loss iteration ->  8260 0.09632349759340286\n",
      "loss iteration ->  8265 0.03159162402153015\n",
      "loss iteration ->  8270 0.25074246525764465\n",
      "loss iteration ->  8275 0.14337675273418427\n",
      "loss iteration ->  8280 0.17454899847507477\n",
      "loss iteration ->  8285 0.2821894586086273\n",
      "loss iteration ->  8290 0.1298634260892868\n",
      "loss iteration ->  8295 0.08088187128305435\n",
      "loss iteration ->  8300 0.12005849927663803\n",
      "loss iteration ->  8305 0.08607561886310577\n",
      "loss iteration ->  8310 0.11525091528892517\n",
      "loss iteration ->  8315 0.2576059103012085\n",
      "loss iteration ->  8320 0.05731411650776863\n",
      "loss iteration ->  8325 0.10282829403877258\n",
      "loss iteration ->  8330 0.10481705516576767\n",
      "loss iteration ->  8335 0.15905281901359558\n",
      "loss iteration ->  8340 0.15686550736427307\n",
      "loss iteration ->  8345 0.1182461678981781\n",
      "loss iteration ->  8350 0.07991732656955719\n",
      "loss iteration ->  8355 0.04074985161423683\n",
      "loss iteration ->  8360 0.08941615372896194\n",
      "loss iteration ->  8365 0.05837935954332352\n",
      "loss iteration ->  8370 0.15111415088176727\n",
      "loss iteration ->  8375 0.12064298242330551\n",
      "loss iteration ->  8380 0.1485130488872528\n",
      "loss iteration ->  8385 0.22027818858623505\n",
      "loss iteration ->  8390 0.0974452942609787\n",
      "loss iteration ->  8395 0.1825893521308899\n",
      "loss iteration ->  8400 0.28619274497032166\n",
      "loss iteration ->  8405 0.022227557376027107\n",
      "loss iteration ->  8410 0.4067917466163635\n",
      "loss iteration ->  8415 0.11830545961856842\n",
      "loss iteration ->  8420 0.1173899695277214\n",
      "loss iteration ->  8425 0.1853804886341095\n",
      "loss iteration ->  8430 0.09177112579345703\n",
      "loss iteration ->  8435 0.13383474946022034\n",
      "loss iteration ->  8440 0.051418039947748184\n",
      "loss iteration ->  8445 0.05198289826512337\n",
      "loss iteration ->  8450 0.2301385998725891\n",
      "loss iteration ->  8455 0.13869646191596985\n",
      "loss iteration ->  8460 0.03930296376347542\n",
      "loss iteration ->  8465 0.16999414563179016\n",
      "loss iteration ->  8470 0.04712075740098953\n",
      "loss iteration ->  8475 0.15217743813991547\n",
      "loss iteration ->  8480 0.10262870788574219\n",
      "loss iteration ->  8485 0.0689145028591156\n",
      "loss iteration ->  8490 0.08871623128652573\n",
      "loss iteration ->  8495 0.062027458101511\n",
      "loss iteration ->  8500 0.03269592672586441\n",
      "loss iteration ->  8505 0.07178273797035217\n",
      "loss iteration ->  8510 0.27729928493499756\n",
      "loss iteration ->  8515 0.02075122483074665\n",
      "loss iteration ->  8520 0.1039152517914772\n",
      "loss iteration ->  8525 0.1611698567867279\n",
      "loss iteration ->  8530 0.0317113883793354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  8535 0.06450759619474411\n",
      "loss iteration ->  8540 0.19247187674045563\n",
      "loss iteration ->  8545 0.10055376589298248\n",
      "loss iteration ->  8550 0.20636311173439026\n",
      "loss iteration ->  8555 0.1475151926279068\n",
      "loss iteration ->  8560 0.07780508697032928\n",
      "loss iteration ->  8565 0.09683836996555328\n",
      "loss iteration ->  8570 0.09604127705097198\n",
      "loss iteration ->  8575 0.2991284132003784\n",
      "loss iteration ->  8580 0.021009620279073715\n",
      "loss iteration ->  8585 0.08532623201608658\n",
      "loss iteration ->  8590 0.029037490487098694\n",
      "loss iteration ->  8595 0.02302762120962143\n",
      "loss iteration ->  8600 0.05373163893818855\n",
      "loss iteration ->  8605 0.11311748623847961\n",
      "loss iteration ->  8610 0.18583686649799347\n",
      "loss iteration ->  8615 0.16462945938110352\n",
      "loss iteration ->  8620 0.4151102900505066\n",
      "loss iteration ->  8625 0.11025398969650269\n",
      "loss iteration ->  8630 0.07747550308704376\n",
      "loss iteration ->  8635 0.20163573324680328\n",
      "loss iteration ->  8640 0.15819160640239716\n",
      "loss iteration ->  8645 0.07728282362222672\n",
      "loss iteration ->  8650 0.05159658193588257\n",
      "loss iteration ->  8655 0.17454493045806885\n",
      "loss iteration ->  8660 0.1699150651693344\n",
      "loss iteration ->  8665 0.059298980981111526\n",
      "loss iteration ->  8670 0.1372990906238556\n",
      "loss iteration ->  8675 0.08969475328922272\n",
      "loss iteration ->  8680 0.07878446578979492\n",
      "loss iteration ->  8685 0.05477549880743027\n",
      "loss iteration ->  8690 0.03680722787976265\n",
      "loss iteration ->  8695 0.14484062790870667\n",
      "loss iteration ->  8700 0.09705669432878494\n",
      "loss iteration ->  8705 0.06698006391525269\n",
      "loss iteration ->  8710 0.13926240801811218\n",
      "loss iteration ->  8715 0.061820853501558304\n",
      "loss iteration ->  8720 0.4021388590335846\n",
      "loss iteration ->  8725 0.05887644737958908\n",
      "loss iteration ->  8730 0.05895207077264786\n",
      "loss iteration ->  8735 0.03808552026748657\n",
      "loss iteration ->  8740 0.09536581486463547\n",
      "loss iteration ->  8745 0.041522540152072906\n",
      "loss iteration ->  8750 0.03991908207535744\n",
      "loss iteration ->  8755 0.22700053453445435\n",
      "loss iteration ->  8760 0.037929728627204895\n",
      "loss iteration ->  8765 0.06917797774076462\n",
      "loss iteration ->  8770 0.04248472675681114\n",
      "loss iteration ->  8775 0.052571311593055725\n",
      "loss iteration ->  8780 0.05826203525066376\n",
      "loss iteration ->  8785 0.261592835187912\n",
      "loss iteration ->  8790 0.15133695304393768\n",
      "loss iteration ->  8795 0.18156647682189941\n",
      "loss iteration ->  8800 0.22455015778541565\n",
      "loss iteration ->  8805 0.07764696329832077\n",
      "loss iteration ->  8810 0.061337921768426895\n",
      "loss iteration ->  8815 0.06336039304733276\n",
      "loss iteration ->  8820 0.07624105364084244\n",
      "loss iteration ->  8825 0.059247929602861404\n",
      "loss iteration ->  8830 0.06884505599737167\n",
      "loss iteration ->  8835 0.052894167602062225\n",
      "loss iteration ->  8840 0.05346172675490379\n",
      "loss iteration ->  8845 0.23277556896209717\n",
      "loss iteration ->  8850 0.06635621935129166\n",
      "loss iteration ->  8855 0.10951097309589386\n",
      "loss iteration ->  8860 0.099210225045681\n",
      "loss iteration ->  8865 0.07595399022102356\n",
      "loss iteration ->  8870 0.08923397213220596\n",
      "loss iteration ->  8875 0.07798494398593903\n",
      "loss iteration ->  8880 0.07786884158849716\n",
      "loss iteration ->  8885 0.07781209796667099\n",
      "loss iteration ->  8890 0.07445071637630463\n",
      "loss iteration ->  8895 0.061045922338962555\n",
      "loss iteration ->  8900 0.033093761652708054\n",
      "loss iteration ->  8905 0.06176569685339928\n",
      "loss iteration ->  8910 0.06718771904706955\n",
      "loss iteration ->  8915 0.05461164191365242\n",
      "loss iteration ->  8920 0.13064062595367432\n",
      "loss iteration ->  8925 0.0980168879032135\n",
      "loss iteration ->  8930 0.09228824079036713\n",
      "loss iteration ->  8935 0.028369717299938202\n",
      "loss iteration ->  8940 0.1374615877866745\n",
      "loss iteration ->  8945 0.03218749910593033\n",
      "loss iteration ->  8950 0.11517457664012909\n",
      "loss iteration ->  8955 0.13919973373413086\n",
      "loss iteration ->  8960 0.1984058916568756\n",
      "loss iteration ->  8965 0.08681467175483704\n",
      "loss iteration ->  8970 0.07098232954740524\n",
      "loss iteration ->  8975 0.20053289830684662\n",
      "loss iteration ->  8980 0.10649493336677551\n",
      "loss iteration ->  8985 0.042576178908348083\n",
      "loss iteration ->  8990 0.029687030240893364\n",
      "loss iteration ->  8995 0.11457449942827225\n",
      "loss iteration ->  9000 0.06149802356958389\n",
      "loss iteration ->  9005 0.16771693527698517\n",
      "loss iteration ->  9010 0.1661747395992279\n",
      "loss iteration ->  9015 0.35551169514656067\n",
      "loss iteration ->  9020 0.02696201391518116\n",
      "loss iteration ->  9025 0.15939949452877045\n",
      "loss iteration ->  9030 0.13654586672782898\n",
      "loss iteration ->  9035 0.021701695397496223\n",
      "loss iteration ->  9040 0.13312482833862305\n",
      "loss iteration ->  9045 0.13026905059814453\n",
      "loss iteration ->  9050 0.15219588577747345\n",
      "loss iteration ->  9055 0.022462425753474236\n",
      "loss iteration ->  9060 0.10382822901010513\n",
      "loss iteration ->  9065 0.11922904849052429\n",
      "loss iteration ->  9070 0.06705162674188614\n",
      "loss iteration ->  9075 0.3865087628364563\n",
      "loss iteration ->  9080 0.12487328797578812\n",
      "loss iteration ->  9085 0.12957240641117096\n",
      "loss iteration ->  9090 0.02895638905465603\n",
      "loss iteration ->  9095 0.19917656481266022\n",
      "loss iteration ->  9100 0.03902747109532356\n",
      "loss iteration ->  9105 0.11479132622480392\n",
      "loss iteration ->  9110 0.06761632114648819\n",
      "loss iteration ->  9115 0.12243254482746124\n",
      "loss iteration ->  9120 0.11882594972848892\n",
      "loss iteration ->  9125 0.08961063623428345\n",
      "loss iteration ->  9130 0.024101270362734795\n",
      "loss iteration ->  9135 0.07441440224647522\n",
      "loss iteration ->  9140 0.04679381474852562\n",
      "loss iteration ->  9145 0.10556226223707199\n",
      "loss iteration ->  9150 0.3395422399044037\n",
      "loss iteration ->  9155 0.15797993540763855\n",
      "loss iteration ->  9160 0.015809547156095505\n",
      "loss iteration ->  9165 0.10124338418245316\n",
      "loss iteration ->  9170 0.05087301880121231\n",
      "loss iteration ->  9175 0.0463123694062233\n",
      "loss iteration ->  9180 0.04702875763177872\n",
      "loss iteration ->  9185 0.1567770540714264\n",
      "loss iteration ->  9190 0.020042013376951218\n",
      "loss iteration ->  9195 0.09039419144392014\n",
      "loss iteration ->  9200 0.04827702045440674\n",
      "loss iteration ->  9205 0.135098397731781\n",
      "loss iteration ->  9210 0.11689775437116623\n",
      "loss iteration ->  9215 0.050978243350982666\n",
      "loss iteration ->  9220 0.07175534218549728\n",
      "loss iteration ->  9225 0.03786034509539604\n",
      "loss iteration ->  9230 0.12022752314805984\n",
      "loss iteration ->  9235 0.030477147549390793\n",
      "loss iteration ->  9240 0.19743612408638\n",
      "loss iteration ->  9245 0.11979985982179642\n",
      "loss iteration ->  9250 0.2043696790933609\n",
      "loss iteration ->  9255 0.1654547154903412\n",
      "loss iteration ->  9260 0.09412369132041931\n",
      "loss iteration ->  9265 0.06272011250257492\n",
      "loss iteration ->  9270 0.18143950402736664\n",
      "loss iteration ->  9275 0.12483438849449158\n",
      "loss iteration ->  9280 0.0457245334982872\n",
      "loss iteration ->  9285 0.1955379694700241\n",
      "loss iteration ->  9290 0.12260479480028152\n",
      "loss iteration ->  9295 0.0823296532034874\n",
      "loss iteration ->  9300 0.08478932082653046\n",
      "loss iteration ->  9305 0.059209633618593216\n",
      "loss iteration ->  9310 0.03921894356608391\n",
      "loss iteration ->  9315 0.24806718528270721\n",
      "loss iteration ->  9320 0.2726043164730072\n",
      "loss iteration ->  9325 0.04327759891748428\n",
      "loss iteration ->  9330 0.08065654337406158\n",
      "loss iteration ->  9335 0.22195877134799957\n",
      "loss iteration ->  9340 0.07462788373231888\n",
      "loss iteration ->  9345 0.20543910562992096\n",
      "loss iteration ->  9350 0.03118717111647129\n",
      "loss iteration ->  9355 0.08629047870635986\n",
      "loss iteration ->  9360 0.09929987043142319\n",
      "loss iteration ->  9365 0.04542158916592598\n",
      "loss iteration ->  9370 0.08876167982816696\n",
      "loss iteration ->  9375 0.03678528219461441\n",
      "loss iteration ->  9380 0.18841123580932617\n",
      "loss iteration ->  9385 0.11990688741207123\n",
      "loss iteration ->  9390 0.2148766815662384\n",
      "loss iteration ->  9395 0.08149395138025284\n",
      "loss iteration ->  9400 0.11387306451797485\n",
      "loss iteration ->  9405 0.04963414743542671\n",
      "loss iteration ->  9410 0.11729972064495087\n",
      "loss iteration ->  9415 0.26601067185401917\n",
      "loss iteration ->  9420 0.094698965549469\n",
      "loss iteration ->  9425 0.0818711519241333\n",
      "loss iteration ->  9430 0.23934786021709442\n",
      "loss iteration ->  9435 0.04139174148440361\n",
      "loss iteration ->  9440 0.07660208642482758\n",
      "loss iteration ->  9445 0.3573806583881378\n",
      "loss iteration ->  9450 0.10936649888753891\n",
      "loss iteration ->  9455 0.17349591851234436\n",
      "loss iteration ->  9460 0.07482755184173584\n",
      "loss iteration ->  9465 0.09050986170768738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  9470 0.13272321224212646\n",
      "loss iteration ->  9475 0.058398738503456116\n",
      "loss iteration ->  9480 0.13326427340507507\n",
      "loss iteration ->  9485 0.022222526371479034\n",
      "loss iteration ->  9490 0.08262727409601212\n",
      "loss iteration ->  9495 0.21095606684684753\n",
      "loss iteration ->  9500 0.15062817931175232\n",
      "loss iteration ->  9505 0.13602733612060547\n",
      "loss iteration ->  9510 0.11317255347967148\n",
      "loss iteration ->  9515 0.015363767743110657\n",
      "loss iteration ->  9520 0.04153067246079445\n",
      "loss iteration ->  9525 0.058646656572818756\n",
      "loss iteration ->  9530 0.14818626642227173\n",
      "loss iteration ->  9535 0.04973645508289337\n",
      "loss iteration ->  9540 0.11808159947395325\n",
      "loss iteration ->  9545 0.28561022877693176\n",
      "loss iteration ->  9550 0.14651888608932495\n",
      "loss iteration ->  9555 0.06485751271247864\n",
      "loss iteration ->  9560 0.08237138390541077\n",
      "loss iteration ->  9565 0.10931790620088577\n",
      "loss iteration ->  9570 0.17916393280029297\n",
      "loss iteration ->  9575 0.038981933146715164\n",
      "loss iteration ->  9580 0.11060064285993576\n",
      "loss iteration ->  9585 0.17389902472496033\n",
      "loss iteration ->  9590 0.08676497638225555\n",
      "loss iteration ->  9595 0.16111944615840912\n",
      "loss iteration ->  9600 0.0854479968547821\n",
      "loss iteration ->  9605 0.017883408814668655\n",
      "loss iteration ->  9610 0.0659327507019043\n",
      "loss iteration ->  9615 0.07599299401044846\n",
      "loss iteration ->  9620 0.2265666425228119\n",
      "loss iteration ->  9625 0.06343996524810791\n",
      "loss iteration ->  9630 0.1523124873638153\n",
      "loss iteration ->  9635 0.2042866349220276\n",
      "loss iteration ->  9640 0.19178098440170288\n",
      "loss iteration ->  9645 0.111515112221241\n",
      "loss iteration ->  9650 0.061782289296388626\n",
      "loss iteration ->  9655 0.12355251610279083\n",
      "loss iteration ->  9660 0.10391152650117874\n",
      "loss iteration ->  9665 0.057354267686605453\n",
      "loss iteration ->  9670 0.07254546135663986\n",
      "loss iteration ->  9675 0.11638117581605911\n",
      "loss iteration ->  9680 0.19224019348621368\n",
      "loss iteration ->  9685 0.1322757750749588\n",
      "loss iteration ->  9690 0.15017461776733398\n",
      "loss iteration ->  9695 0.11438601464033127\n",
      "loss iteration ->  9700 0.08679542690515518\n",
      "loss iteration ->  9705 0.10401180386543274\n",
      "loss iteration ->  9710 0.03994186222553253\n",
      "loss iteration ->  9715 0.05902896821498871\n",
      "loss iteration ->  9720 0.054074276238679886\n",
      "loss iteration ->  9725 0.04031703248620033\n",
      "loss iteration ->  9730 0.09194230288267136\n",
      "loss iteration ->  9735 0.07186491787433624\n",
      "loss iteration ->  9740 0.17380157113075256\n",
      "loss iteration ->  9745 0.1172916367650032\n",
      "loss iteration ->  9750 0.09922343492507935\n",
      "loss iteration ->  9755 0.2420116513967514\n",
      "loss iteration ->  9760 0.2643716037273407\n",
      "loss iteration ->  9765 0.2287534922361374\n",
      "loss iteration ->  9770 0.06385007500648499\n",
      "loss iteration ->  9775 0.07120836526155472\n",
      "loss iteration ->  9780 0.09168373048305511\n",
      "loss iteration ->  9785 0.05532418191432953\n",
      "loss iteration ->  9790 0.08321162313222885\n",
      "loss iteration ->  9795 0.10374448448419571\n",
      "loss iteration ->  9800 0.0671318992972374\n",
      "loss iteration ->  9805 0.11199624836444855\n",
      "loss iteration ->  9810 0.060136742889881134\n",
      "loss iteration ->  9815 0.18597650527954102\n",
      "loss iteration ->  9820 0.0873088538646698\n",
      "loss iteration ->  9825 0.07795869559049606\n",
      "loss iteration ->  9830 0.13575057685375214\n",
      "loss iteration ->  9835 0.04073944687843323\n",
      "loss iteration ->  9840 0.23857074975967407\n",
      "loss iteration ->  9845 0.11862677335739136\n",
      "loss iteration ->  9850 0.12165957689285278\n",
      "loss iteration ->  9855 0.06868451088666916\n",
      "loss iteration ->  9860 0.19365017116069794\n",
      "loss iteration ->  9865 0.07157711684703827\n",
      "loss iteration ->  9870 0.045229472219944\n",
      "loss iteration ->  9875 0.16379031538963318\n",
      "loss iteration ->  9880 0.09316875785589218\n",
      "loss iteration ->  9885 0.018714290112257004\n",
      "loss iteration ->  9890 0.03722497075796127\n",
      "loss iteration ->  9895 0.07227815687656403\n",
      "loss iteration ->  9900 0.051839154213666916\n",
      "loss iteration ->  9905 0.1638311743736267\n",
      "loss iteration ->  9910 0.11738090217113495\n",
      "loss iteration ->  9915 0.02854897640645504\n",
      "loss iteration ->  9920 0.41831985116004944\n",
      "loss iteration ->  9925 0.03781414031982422\n",
      "loss iteration ->  9930 0.17111188173294067\n",
      "loss iteration ->  9935 0.19249552488327026\n",
      "loss iteration ->  9940 0.08811543881893158\n",
      "loss iteration ->  9945 0.05492743104696274\n",
      "loss iteration ->  9950 0.12556661665439606\n",
      "loss iteration ->  9955 0.09401835501194\n",
      "loss iteration ->  9960 0.046172477304935455\n",
      "loss iteration ->  9965 0.03836078569293022\n",
      "loss iteration ->  9970 0.0493677482008934\n",
      "loss iteration ->  9975 0.04291556775569916\n",
      "loss iteration ->  9980 0.14639520645141602\n",
      "loss iteration ->  9985 0.09968367218971252\n",
      "loss iteration ->  9990 0.07892271131277084\n",
      "loss iteration ->  9995 0.02320070192217827\n",
      "loss iteration ->  10000 0.05391402915120125\n",
      "loss iteration ->  10005 0.14100411534309387\n",
      "loss iteration ->  10010 0.032818280160427094\n",
      "loss iteration ->  10015 0.03492221236228943\n",
      "loss iteration ->  10020 0.09008529037237167\n",
      "loss iteration ->  10025 0.16362348198890686\n",
      "loss iteration ->  10030 0.06905663013458252\n",
      "loss iteration ->  10035 0.08235223591327667\n",
      "loss iteration ->  10040 0.0727805346250534\n",
      "loss iteration ->  10045 0.16023582220077515\n",
      "loss iteration ->  10050 0.05115430802106857\n",
      "loss iteration ->  10055 0.0710400864481926\n",
      "loss iteration ->  10060 0.12084700912237167\n",
      "loss iteration ->  10065 0.10096672177314758\n",
      "loss iteration ->  10070 0.044148415327072144\n",
      "loss iteration ->  10075 0.13253933191299438\n",
      "loss iteration ->  10080 0.16960816085338593\n",
      "loss iteration ->  10085 0.06859313696622849\n",
      "loss iteration ->  10090 0.22051897644996643\n",
      "loss iteration ->  10095 0.020415330305695534\n",
      "loss iteration ->  10100 0.06441226601600647\n",
      "loss iteration ->  10105 0.11909525841474533\n",
      "loss iteration ->  10110 0.033083196729421616\n",
      "loss iteration ->  10115 0.31974104046821594\n",
      "loss iteration ->  10120 0.2334267944097519\n",
      "loss iteration ->  10125 0.02243516780436039\n",
      "loss iteration ->  10130 0.07129562646150589\n",
      "loss iteration ->  10135 0.05988585948944092\n",
      "loss iteration ->  10140 0.08864259719848633\n",
      "loss iteration ->  10145 0.1341291069984436\n",
      "loss iteration ->  10150 0.032126277685165405\n",
      "loss iteration ->  10155 0.08444264531135559\n",
      "loss iteration ->  10160 0.012923557311296463\n",
      "loss iteration ->  10165 0.04078986495733261\n",
      "loss iteration ->  10170 0.0740734115242958\n",
      "loss iteration ->  10175 0.11922216415405273\n",
      "loss iteration ->  10180 0.23869065940380096\n",
      "loss iteration ->  10185 0.15032094717025757\n",
      "loss iteration ->  10190 0.02008930593729019\n",
      "loss iteration ->  10195 0.1849740594625473\n",
      "loss iteration ->  10200 0.06839331984519958\n",
      "loss iteration ->  10205 0.2676600217819214\n",
      "loss iteration ->  10210 0.08361151814460754\n",
      "loss iteration ->  10215 0.08204814791679382\n",
      "loss iteration ->  10220 0.18037301301956177\n",
      "loss iteration ->  10225 0.18030251562595367\n",
      "loss iteration ->  10230 0.025986438617110252\n",
      "loss iteration ->  10235 0.34872201085090637\n",
      "loss iteration ->  10240 0.03475138917565346\n",
      "loss iteration ->  10245 0.062279149889945984\n",
      "loss iteration ->  10250 0.245331272482872\n",
      "loss iteration ->  10255 0.06543295085430145\n",
      "loss iteration ->  10260 0.04495299607515335\n",
      "loss iteration ->  10265 0.3163038492202759\n",
      "loss iteration ->  10270 0.180219367146492\n",
      "loss iteration ->  10275 0.050325434654951096\n",
      "loss iteration ->  10280 0.07807794958353043\n",
      "loss iteration ->  10285 0.21540886163711548\n",
      "loss iteration ->  10290 0.09123782813549042\n",
      "loss iteration ->  10295 0.06331249326467514\n",
      "loss iteration ->  10300 0.10090334713459015\n",
      "loss iteration ->  10305 0.04997296258807182\n",
      "loss iteration ->  10310 0.07342121005058289\n",
      "loss iteration ->  10315 0.2444566935300827\n",
      "loss iteration ->  10320 0.05521049350500107\n",
      "loss iteration ->  10325 0.04479673132300377\n",
      "loss iteration ->  10330 0.03709489479660988\n",
      "loss iteration ->  10335 0.036936499178409576\n",
      "loss iteration ->  10340 0.09578368067741394\n",
      "loss iteration ->  10345 0.05174177512526512\n",
      "loss iteration ->  10350 0.11488793790340424\n",
      "loss iteration ->  10355 0.14919671416282654\n",
      "loss iteration ->  10360 0.10269699990749359\n",
      "loss iteration ->  10365 0.04500151053071022\n",
      "loss iteration ->  10370 0.05981332063674927\n",
      "loss iteration ->  10375 0.2559659779071808\n",
      "loss iteration ->  10380 0.03336941450834274\n",
      "loss iteration ->  10385 0.08282347023487091\n",
      "loss iteration ->  10390 0.02946496568620205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  10395 0.14905601739883423\n",
      "loss iteration ->  10400 0.0852663516998291\n",
      "loss iteration ->  10405 0.17084020376205444\n",
      "loss iteration ->  10410 0.13847079873085022\n",
      "loss iteration ->  10415 0.0314183235168457\n",
      "loss iteration ->  10420 0.03999779000878334\n",
      "loss iteration ->  10425 0.035521287471055984\n",
      "loss iteration ->  10430 0.12578700482845306\n",
      "loss iteration ->  10435 0.1575891226530075\n",
      "loss iteration ->  10440 0.031998682767152786\n",
      "loss iteration ->  10445 0.1453377902507782\n",
      "loss iteration ->  10450 0.14822643995285034\n",
      "loss iteration ->  10455 0.09382081776857376\n",
      "loss iteration ->  10460 0.07721716910600662\n",
      "loss iteration ->  10465 0.1859191656112671\n",
      "loss iteration ->  10470 0.20811542868614197\n",
      "loss iteration ->  10475 0.030336137861013412\n",
      "loss iteration ->  10480 0.13073484599590302\n",
      "loss iteration ->  10485 0.03567839786410332\n",
      "loss iteration ->  10490 0.09860625118017197\n",
      "loss iteration ->  10495 0.1532752811908722\n",
      "loss iteration ->  10500 0.038285691291093826\n",
      "loss iteration ->  10505 0.07695721834897995\n",
      "loss iteration ->  10510 0.11844129115343094\n",
      "loss iteration ->  10515 0.11424747854471207\n",
      "loss iteration ->  10520 0.07609288394451141\n",
      "loss iteration ->  10525 0.05234373360872269\n",
      "loss iteration ->  10530 0.16517245769500732\n",
      "loss iteration ->  10535 0.06109239161014557\n",
      "loss iteration ->  10540 0.028133006766438484\n",
      "loss iteration ->  10545 0.1562747210264206\n",
      "loss iteration ->  10550 0.07887662202119827\n",
      "loss iteration ->  10555 0.022918695583939552\n",
      "loss iteration ->  10560 0.10795886069536209\n",
      "loss iteration ->  10565 0.03922099247574806\n",
      "loss iteration ->  10570 0.03142896667122841\n",
      "loss iteration ->  10575 0.12527166306972504\n",
      "loss iteration ->  10580 0.047543466091156006\n",
      "loss iteration ->  10585 0.020498385652899742\n",
      "loss iteration ->  10590 0.03349560871720314\n",
      "loss iteration ->  10595 0.14098533987998962\n",
      "loss iteration ->  10600 0.014805094338953495\n",
      "loss iteration ->  10605 0.11057271808385849\n",
      "loss iteration ->  10610 0.05865145102143288\n",
      "loss iteration ->  10615 0.03238062933087349\n",
      "loss iteration ->  10620 0.13863632082939148\n",
      "loss iteration ->  10625 0.03534304350614548\n",
      "loss iteration ->  10630 0.41637784242630005\n",
      "loss iteration ->  10635 0.019261745736002922\n",
      "loss iteration ->  10640 0.02092134580016136\n",
      "loss iteration ->  10645 0.032125074416399\n",
      "loss iteration ->  10650 0.33071833848953247\n",
      "loss iteration ->  10655 0.05560302734375\n",
      "loss iteration ->  10660 0.09202555567026138\n",
      "loss iteration ->  10665 0.056984469294548035\n",
      "loss iteration ->  10670 0.07650704681873322\n",
      "loss iteration ->  10675 0.09185953438282013\n",
      "loss iteration ->  10680 0.04351295903325081\n",
      "loss iteration ->  10685 0.03372994065284729\n",
      "loss iteration ->  10690 0.021507225930690765\n",
      "loss iteration ->  10695 0.034567028284072876\n",
      "loss iteration ->  10700 0.08265255391597748\n",
      "loss iteration ->  10705 0.055689744651317596\n",
      "loss iteration ->  10710 0.12468140572309494\n",
      "loss iteration ->  10715 0.1563650369644165\n",
      "loss iteration ->  10720 0.18211832642555237\n",
      "loss iteration ->  10725 0.22073771059513092\n",
      "loss iteration ->  10730 0.020298760384321213\n",
      "loss iteration ->  10735 0.12746235728263855\n",
      "loss iteration ->  10740 0.13880182802677155\n",
      "loss iteration ->  10745 0.015228589996695518\n",
      "loss iteration ->  10750 0.10060834139585495\n",
      "loss iteration ->  10755 0.1717713624238968\n",
      "loss iteration ->  10760 0.11356408894062042\n",
      "loss iteration ->  10765 0.09204696863889694\n",
      "loss iteration ->  10770 0.12841463088989258\n",
      "loss iteration ->  10775 0.060494136065244675\n",
      "loss iteration ->  10780 0.06884381920099258\n",
      "loss iteration ->  10785 0.05993632227182388\n",
      "loss iteration ->  10790 0.05184226483106613\n",
      "loss iteration ->  10795 0.037688225507736206\n",
      "loss iteration ->  10800 0.024847548454999924\n",
      "loss iteration ->  10805 0.03874882683157921\n",
      "loss iteration ->  10810 0.06602155417203903\n",
      "loss iteration ->  10815 0.15617944300174713\n",
      "loss iteration ->  10820 0.2624036371707916\n",
      "loss iteration ->  10825 0.22088897228240967\n",
      "loss iteration ->  10830 0.08882162719964981\n",
      "loss iteration ->  10835 0.054855965077877045\n",
      "loss iteration ->  10840 0.07149266451597214\n",
      "loss iteration ->  10845 0.05842295289039612\n",
      "loss iteration ->  10850 0.09734485298395157\n",
      "loss iteration ->  10855 0.09535881131887436\n",
      "loss iteration ->  10860 0.1613759547472\n",
      "loss iteration ->  10865 0.05638948455452919\n",
      "loss iteration ->  10870 0.02117825858294964\n",
      "loss iteration ->  10875 0.17680829763412476\n",
      "loss iteration ->  10880 0.06671474128961563\n",
      "loss iteration ->  10885 0.12201562523841858\n",
      "loss iteration ->  10890 0.01346319168806076\n",
      "loss iteration ->  10895 0.05600135773420334\n",
      "loss iteration ->  10900 0.030130203813314438\n",
      "loss iteration ->  10905 0.17883546650409698\n",
      "loss iteration ->  10910 0.27752697467803955\n",
      "loss iteration ->  10915 0.040676575154066086\n",
      "loss iteration ->  10920 0.1832275241613388\n",
      "loss iteration ->  10925 0.03174866363406181\n",
      "loss iteration ->  10930 0.11119234561920166\n",
      "loss iteration ->  10935 0.026566719636321068\n",
      "loss iteration ->  10940 0.14589424431324005\n",
      "loss iteration ->  10945 0.013458655215799809\n",
      "loss iteration ->  10950 0.15448491275310516\n",
      "loss iteration ->  10955 0.061719585210084915\n",
      "loss iteration ->  10960 0.037844493985176086\n",
      "loss iteration ->  10965 0.1285029500722885\n",
      "loss iteration ->  10970 0.16864793002605438\n",
      "loss iteration ->  10975 0.1877669245004654\n",
      "loss iteration ->  10980 0.12318529933691025\n",
      "loss iteration ->  10985 0.1052914559841156\n",
      "loss iteration ->  10990 0.1128004863858223\n",
      "loss iteration ->  10995 0.22536607086658478\n",
      "loss iteration ->  11000 0.0348237082362175\n",
      "loss iteration ->  11005 0.0684584379196167\n",
      "loss iteration ->  11010 0.06971355527639389\n",
      "loss iteration ->  11015 0.12301187217235565\n",
      "loss iteration ->  11020 0.059031419456005096\n",
      "loss iteration ->  11025 0.017686044797301292\n",
      "loss iteration ->  11030 0.03674725443124771\n",
      "loss iteration ->  11035 0.09312092512845993\n",
      "loss iteration ->  11040 0.1101740151643753\n",
      "loss iteration ->  11045 0.04288050904870033\n",
      "loss iteration ->  11050 0.1909913569688797\n",
      "loss iteration ->  11055 0.11460575461387634\n",
      "loss iteration ->  11060 0.2582998275756836\n",
      "loss iteration ->  11065 0.12786567211151123\n",
      "loss iteration ->  11070 0.04301993548870087\n",
      "loss iteration ->  11075 0.026391496881842613\n",
      "loss iteration ->  11080 0.06562425941228867\n",
      "loss iteration ->  11085 0.06476634740829468\n",
      "loss iteration ->  11090 0.06563479453325272\n",
      "loss iteration ->  11095 0.0518396720290184\n",
      "loss iteration ->  11100 0.046065665781497955\n",
      "loss iteration ->  11105 0.024528078734874725\n",
      "loss iteration ->  11110 0.2881338894367218\n",
      "loss iteration ->  11115 0.07810399681329727\n",
      "loss iteration ->  11120 0.20102624595165253\n",
      "loss iteration ->  11125 0.1428617238998413\n",
      "loss iteration ->  11130 0.22339536249637604\n",
      "loss iteration ->  11135 0.08014825731515884\n",
      "loss iteration ->  11140 0.015386968851089478\n",
      "loss iteration ->  11145 0.1814916580915451\n",
      "loss iteration ->  11150 0.1318305879831314\n",
      "loss iteration ->  11155 0.08440780639648438\n",
      "loss iteration ->  11160 0.3776686191558838\n",
      "loss iteration ->  11165 0.16509810090065002\n",
      "loss iteration ->  11170 0.0951811671257019\n",
      "loss iteration ->  11175 0.022730598226189613\n",
      "loss iteration ->  11180 0.10299146175384521\n",
      "loss iteration ->  11185 0.15947724878787994\n",
      "loss iteration ->  11190 0.02256542257964611\n",
      "loss iteration ->  11195 0.05934737250208855\n",
      "loss iteration ->  11200 0.05645807832479477\n",
      "loss iteration ->  11205 0.12263038009405136\n",
      "loss iteration ->  11210 0.08065947890281677\n",
      "loss iteration ->  11215 0.08033125102519989\n",
      "loss iteration ->  11220 0.0397445373237133\n",
      "loss iteration ->  11225 0.1347208321094513\n",
      "loss iteration ->  11230 0.13067761063575745\n",
      "loss iteration ->  11235 0.023111611604690552\n",
      "loss iteration ->  11240 0.018570249900221825\n",
      "loss iteration ->  11245 0.15744644403457642\n",
      "loss iteration ->  11250 0.10059016197919846\n",
      "loss iteration ->  11255 0.16062821447849274\n",
      "loss iteration ->  11260 0.06607071310281754\n",
      "loss iteration ->  11265 0.05168091505765915\n",
      "loss iteration ->  11270 0.10308034718036652\n",
      "loss iteration ->  11275 0.050135817378759384\n",
      "loss iteration ->  11280 0.07851602137088776\n",
      "loss iteration ->  11285 0.04160596430301666\n",
      "loss iteration ->  11290 0.0608258992433548\n",
      "loss iteration ->  11295 0.03653458505868912\n",
      "loss iteration ->  11300 0.1745811104774475\n",
      "loss iteration ->  11305 0.09905161708593369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss iteration ->  11310 0.0949733555316925\n",
      "loss iteration ->  11315 0.03202815353870392\n",
      "loss iteration ->  11320 0.06125709414482117\n",
      "loss iteration ->  11325 0.07108493149280548\n",
      "loss iteration ->  11330 0.0418478362262249\n",
      "loss iteration ->  11335 0.08841736614704132\n",
      "loss iteration ->  11340 0.0266244038939476\n",
      "loss iteration ->  11345 0.0638982504606247\n",
      "loss iteration ->  11350 0.19188709557056427\n",
      "loss iteration ->  11355 0.16428855061531067\n",
      "loss iteration ->  11360 0.08224275708198547\n",
      "loss iteration ->  11365 0.016864387318491936\n",
      "loss iteration ->  11370 0.021765194833278656\n",
      "loss iteration ->  11375 0.19938978552818298\n",
      "loss iteration ->  11380 0.07113750278949738\n",
      "loss iteration ->  11385 0.2062709480524063\n",
      "loss iteration ->  11390 0.057162657380104065\n",
      "loss iteration ->  11395 0.07451138645410538\n",
      "loss iteration ->  11400 0.03648408129811287\n",
      "loss iteration ->  11405 0.15443438291549683\n",
      "loss iteration ->  11410 0.20756515860557556\n",
      "loss iteration ->  11415 0.13377000391483307\n",
      "loss iteration ->  11420 0.09314918518066406\n",
      "loss iteration ->  11425 0.03620157763361931\n",
      "loss iteration ->  11430 0.031148068606853485\n",
      "loss iteration ->  11435 0.028201153501868248\n",
      "loss iteration ->  11440 0.13639643788337708\n",
      "loss iteration ->  11445 0.117973193526268\n",
      "loss iteration ->  11450 0.04102626070380211\n",
      "loss iteration ->  11455 0.5293383598327637\n",
      "loss iteration ->  11460 0.10157464444637299\n",
      "loss iteration ->  11465 0.07358945161104202\n",
      "loss iteration ->  11470 0.06634137034416199\n",
      "loss iteration ->  11475 0.03858264163136482\n",
      "loss iteration ->  11480 0.044210780411958694\n",
      "loss iteration ->  11485 0.134721577167511\n",
      "loss iteration ->  11490 0.040744416415691376\n",
      "loss iteration ->  11495 0.09855754673480988\n",
      "loss iteration ->  11500 0.018718142062425613\n",
      "loss iteration ->  11505 0.09205150604248047\n",
      "loss iteration ->  11510 0.03904277831315994\n",
      "loss iteration ->  11515 0.03906574472784996\n",
      "loss iteration ->  11520 0.22322171926498413\n",
      "loss iteration ->  11525 0.043082091957330704\n",
      "loss iteration ->  11530 0.17836228013038635\n",
      "loss iteration ->  11535 0.07288975268602371\n",
      "loss iteration ->  11540 0.0996740311384201\n",
      "loss iteration ->  11545 0.06070787459611893\n",
      "loss iteration ->  11550 0.08587764948606491\n",
      "loss iteration ->  11555 0.017786787822842598\n",
      "loss iteration ->  11560 0.0931805968284607\n",
      "loss iteration ->  11565 0.16056601703166962\n",
      "loss iteration ->  11570 0.10543996840715408\n",
      "loss iteration ->  11575 0.40756097435951233\n",
      "loss iteration ->  11580 0.09812917560338974\n",
      "loss iteration ->  11585 0.14714117348194122\n",
      "loss iteration ->  11590 0.08676785975694656\n",
      "loss iteration ->  11595 0.1314322054386139\n",
      "loss iteration ->  11600 0.08738505840301514\n",
      "loss iteration ->  11605 0.10282349586486816\n",
      "loss iteration ->  11610 0.08082038164138794\n",
      "loss iteration ->  11615 0.09275977313518524\n",
      "loss iteration ->  11620 0.015394678339362144\n",
      "loss iteration ->  11625 0.03533942252397537\n",
      "loss iteration ->  11630 0.04451406002044678\n",
      "loss iteration ->  11635 0.05427258834242821\n",
      "loss iteration ->  11640 0.15608753263950348\n",
      "loss iteration ->  11645 0.08837967365980148\n",
      "loss iteration ->  11650 0.07705125957727432\n",
      "loss iteration ->  11655 0.08719503879547119\n",
      "loss iteration ->  11660 0.16961611807346344\n",
      "loss iteration ->  11665 0.05590298771858215\n",
      "loss iteration ->  11670 0.13919824361801147\n",
      "loss iteration ->  11675 0.09333875775337219\n",
      "loss iteration ->  11680 0.10610123723745346\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            iteration_no = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                iteration_no += 1\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        if iteration_no % 5 == 0:\n",
    "                            print(\"loss iteration -> \", iteration_no, loss.item())\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model, INFERENCE_PATH)\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "# Train and evaluate\n",
    "dataset_sizes = {'train': len(training_set), 'val': len(validation_set)}\n",
    "# Dummy dataset\n",
    "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d1904",
   "metadata": {},
   "source": [
    "### Testing and evaluation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b8e9218",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = data_pipeline_pytorch_smaller_dataset.test_dataloader\n",
    "model_ft.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_preds += preds.cpu().numpy().tolist()\n",
    "        test_labels += labels.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59d72b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0294\n",
      "Test Accuracy: 0.9921\n",
      "Confusion Matrix:\n",
      " [[3186    9]\n",
      " [  40 2969]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Calculate the test accuracy and confusion matrix\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "conf_mat = confusion_matrix(test_labels, test_preds)\n",
    "print(\"Test Loss: {:.4f}\".format(test_loss/len(data_pipeline_pytorch_smaller_dataset.test_dataset)))\n",
    "print(\"Test Accuracy: {:.4f}\".format(test_acc))\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84900d",
   "metadata": {},
   "source": [
    "### Download the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d6a916d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, INFERENCE_PATH)\n",
    "inference_model = torch.load(INFERENCE_PATH)\n",
    "inference_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993e631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
